{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPORT ACTIVITATE IUNIE 2017-SEPTEMBRIE 2017\n",
    "\n",
    "- <i><font color='#848484'><b><u>Laurentiu-Gheorghe PICIU</b></u> (4E Software & Facultatea de Automatică și Calculatoare - UPB)</font></i> <br>\n",
    "- <i><font color='#848484'><b><u>Andrei SIMION-CONSTANTINESCU</b></u> (4E Software & Facultatea de Automatică și Calculatoare - UPB)</font></i> <br>\n",
    "\n",
    "## Prezentare generală\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În domeniul Învățării Automate (Machine Learning), orice problemă are ca punct de plecare existența unor date. O pereche de forma $(x^{(i)}, y^{(i)})$ constituie un exemplu din setul de date, unde $x^{(i)}$ reprezintă variabilele de intrare (predictori), iar $y^{(i)}$ reprezintă variabila target. Astfel, dându-se un set de date, scopul este să se găsească o funcție $h: X \\rightarrow Y$, cu proprietatea că $h(x)$ este un predictor bun pentru valoarea corespunzătoare - $y$. În momentul în care varibila target este continuă, atunci interacționăm cu o problemă de **regresie**. Altfel, dacă $y$ aparține unei mulțimi cu un număr mic de valori discrete, atunci problema este una de **clasificare**.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Atât în cazul regresiei liniare, cât și în cazul regresiei logistice (clasificare), se dorește găsirea unui **hiperplan** care să aproximeze cât mai bine punctele din setul de date. Ecuația hiperplanului este data de înmulțirea dintre parametrii $\\theta$ (pe care dorim să îi îmbunătățim prin antrenament) și variabilele predictor:\n",
    "</p>\n",
    "\n",
    "$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n}x_{n} = \\begin{bmatrix} \\theta_{0} &  \\theta_{1} & \\theta_{2} & ... & \\theta_{n}\\end{bmatrix}\\begin{bmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\\\ .. \\\\ x_{n}\\end{bmatrix} = \\theta^Tx$, unde $n = $numărul predictorilor și $x_{0} = 1$.\n",
    "\n",
    "1. <h6>Problema clasificării</h6>\n",
    "Pentru ca funcția ipoteză să întoarcă valori în intervalul $[0, 1]$ s-a introdus funcția **sigmoid** $g(z) = \\frac{1}{1 + e^{-z}} \\implies h_{\\theta}(x) = g(\\theta^Tx)$.\n",
    "<img src=\"img/sigmoid.png\" alt=\"Graficul functiei sigmoid\" style=\"width: 450px;\"/>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "    Sigmoid-ul este de ajutor pentru clasificare binară, dar și pentru clasificare multinomială **One-vs-All**. Pentru generalizarea clasificării multinomiale, se folosește funcția **softmax**, care este o generalizare a sigmoid-ului. Pentru a putea fi folosit softmax-ul, trebuie ca variabila target sa fie **one-hot**, astfel încât funcția softmax să ofere K probabilități (K = numărul de clase):\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    $h_{\\theta}(x^{(i)}) = \\begin{bmatrix} p(y^{(i)} = 1\\,|\\,x^{(i)}; \\theta) \\\\ p(y^{(i)} = 2\\,|\\,x^{(i)}; \\theta)  \\\\ .. \\\\ p(y^{(i)} = k\\,|\\,x^{(i)}; \\theta)\\end{bmatrix} = \\frac{1}{\\sum_{j=1}^{k}e^{\\theta_j^Tx^{(i)}}}\\begin{bmatrix} e^{\\theta_1^Tx^{(i)}} \\\\ e^{\\theta_2^Tx^{(i)}}  \\\\ .. \\\\ e^{\\theta_k^Tx^{(i)}}\\end{bmatrix}$\n",
    "    \n",
    "</p>\n",
    "\n",
    "2. <h6>Funcția de cost</h6>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Evaluarea convergenței unui model se face cu ajutorul **funcției de cost**. Pentru clasificare se folosește funcția de cost numită **cross-entropy**.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    $J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}Cost(h_{\\theta}(x^{(i)}), y^{(i)})$, unde $m = $numărul de observații.\n",
    "    </p><br>\n",
    "    $Cost(h_{\\theta}(x), y) = -log(h_{\\theta}(x))$, dacă $y = 1$ <br>\n",
    "    $Cost(h_{\\theta}(x), y) = -log(1 - h_{\\theta}(x))$, dacă $y = 0$ <br><br>\n",
    "    $\\implies J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}log(h_{\\theta}(x^{(i)})) + (1 - y^{(i)})log(1 - h_{\\theta}(x^{(i)}))]$\n",
    "\n",
    "2. <h6>Tunarea parametrilor</h6>\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru îmbunătățirea parametrilor, se va ține cont de derivatele parțiale ale funcției de cost în funcție de fiecare parametru $\\theta_j$, aplicându-se metoda **gradientului descendent**, care modifică parametrii astfel încât funcția de cost să descrească.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    $Repeta\\;\\{ \\\\\n",
    "    \\quad \\theta_j := \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta)\\\\\n",
    "    \\}$ <br>\n",
    "    \n",
    "    $Repeta\\;\\{ \\\\\n",
    "    \\quad \\theta_j := \\theta_j - \\frac{\\alpha}{m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)} \\\\\n",
    "    \\}$\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    Varianta vectorizată: $\\theta := \\theta - \\frac{\\alpha}{m}X^T \\cdot residual$\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În această perioadă, activitatea noastră a avut ca scop înțelegerea conceptelor care stau în spatele modelelor de regresie/clasificare, precum și construirea unor astfel de modele. În principal, tot ceea ce s-a construit, a avut ca punct de plecare setul de date **MNIST**, care conține 70,000 de imagini de dimensiune 28x28, reprezentând cifrele de la 0 la 9 scrise de mână. Pe baza acestor imagini, s-au antrenat modele de clasificare din ce în ce mai complexe, pornind de la **regresie logistică**, **KNN** și **SVM**, avansând la **rețele neuronale complet conectate (fully-connected)** și terminând cu **rețele neuronale de convoluție (CNN)**. Modelele au fost antrenate/testate folosind limbajul de programare **Python**, fiind scrise inițial folosind numai operații vectorizate **NumPy**, urmând ca în final să rescriem totul cu ajutorul bibliotecii **TensorFlow**. Pentru fiecare model, setul de date a fost împărțit în date de antrenare (70%), date de validare în timpul antrenamentului (15%), precum și date de testare la finalul antrenamentului (15%). În plus, variabilele predictor (cei 784 de pixeli) au fost scalate între 0 și 1, folosind **scalarea (normalizarea) Min-Max**, ce face ca ele să \"cântărească\" la fel de mult și, în plus, crește abilitatea modelului de a învăța. Formula folosită pentru normalizare este: $X_{norm} = \\frac{X - X_{min}}{X_{max}-X_{min}}$.\n",
    "</p>\n",
    "\n",
    "Modelele au fost antrenate **stochastic**, datele fiind procesate în mini-batch-uri și, în plus, s-au folosit metode care vizează:\n",
    "+ înlăturarea **overfitting-ului** (\"învățare pe de rost\"): regularizare, dropout;\n",
    "+ optimizarea procesului de găsire a minimului funcției de cost: momentum, descreștere a coeficientului de învățare (learning rate decay)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script src=\"https://gist.github.com/jonschlinkert/5854601.js\"></script>\n",
    "# Conținut\n",
    "  1. [<font color='black'>Regresie logistică</font>](#chapter-1)\n",
    "  2. [<font color='black'>KNN</font>](#chapter-2)\n",
    "  3. [<font color='black'>SVM</font>](#chapter-3)\n",
    "  4. [<font color='black'>Rețele neuronale complet conectate</font>](#chapter-4)\n",
    "  5. [<font color='black'>Rețele neuronale de convoluție (CNN)</font>](#chapter-5)\n",
    "  6. [<font color='black'>Fereastra glisantă</font>](#chapter-6)\n",
    "  7. [<font color='black'>Comportament CNN pe scene care înglobează mai mult de o imagine</font>](#chapter-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresie logistică <a id='chapter-1'></a>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Fiind vorba de 784 variabile predictor (784 pixeli) și de 10 categorii, s-au folosit 10x785 de parametri (câte un regresor pentru fiecare categorie). Aceștia au fost inițializați cu valoarea 0. Hiperparametrii folosiți pentru antrenament sunt urmatorii: **număr de epoci**: 25; **coeficient de învățare**: 0.001; **dimensiunea unui mini-batch**: 10; **coeficient regularizare**: 0.0001; **momentum**: 0.9; **factor decay**: 0.65.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În timpul antrenamentului au fost înregistrate la fiecare epocă loguri relevante pentru a observa modul în care converge modelul (costul per mini-batch, target real vs target prezis, cost + acuratețe pe seturile de date de antrenament și validare, timpul scurs pe ecopa respectivă):\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"img/logreg_logs.png\" alt=\"Logs\" style=\"width: 550px;\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În urma antrenamentului modelului (care a durat aproximativ 60 de secunde), s-au obținut următoarele valori pentru acuratețe:\n",
    "</p>\n",
    "\n",
    "+ pe setul de date folosit pentru antrenament: 92.45%\n",
    "+ pe setul de date de validare: 91.94%\n",
    "+ pe setul de date de test: 92.27%\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Convergența modelului se poate observa urmărind cele 2 grafice de mai jos:\n",
    "\n",
    "<img align=\"center\" src=\"img/logreg_cost_train_val2.png\" alt=\"Cost antrenament, validare\" style=\"width: 1000px;\"/> <br>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "S-au folosit tehnici de afișare a celor 10 regresoare și s-a observat faptul că ele iau forma cifrei pe care doresc să o clasifice (adică parametrii vor avea valori foarte mari pozitive acolo unde pixelii sunt activați și valori foarte mari negative acolo unde pixelii sunt neactivați). Motivul apariției acestui fenomen este faptul că regresorul care încearcă să clasifice cifra $i, i = 0 ... 9$ trebuie să întoarcă o valoare cât mai mare pentru o imagine care are target $= i$ și o valoare cât mai mică pentru o imagine cu target $!= i$, astfel încât aplicarea funcției softmax pentru predicție să scaleze aceste valori corespunzător între 0 și 1 pentru oferirea unei probabilități. Mai mult, odată cu afișarea celor 10 vectori $\\theta$ ajungem la concluzia că **regresia logistică este o metodă de clasificare pixel-wise (nu învață trasături/caracteristici)**.\n",
    "</p>\n",
    "\n",
    "<img src=\"img/logreg_thetas.png\" alt=\"Theta\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru a observa în ce măsură s-a făcut predicția pe setul de date de test, s-au folosit procedee din domeniul statisticii precum: matricea de confuzie, precizie (cât din ce a fost prezis este și corect), recall (cât din ce este corect a fost prezis), scor F (media armonică a preciziei și a recall-ului):\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img align=\"center\" src=\"img/logreg_confuzie.png\" alt=\"Matrice confuzie\" style=\"width: 450px;\"/>\n",
    "<br><br>\n",
    "\n",
    "| Precizie | Recall | F | N Obs\n",
    "--- | --- | --- | --- | ---\n",
    "0 | 0.95 | 0.97 | 0.96 | 1046\n",
    "1 | 0.96 | 0.97 | 0.97 | 1154\n",
    "2 | 0.94 | 0.88 | 0.91 | 1120\n",
    "3 | 0.90 | 0.92 | 0.91 | 1090\n",
    "4 | 0.91 | 0.93 | 0.92 | 1056\n",
    "5 | 0.89 | 0.85 | 0.87 | 965\n",
    "6 | 0.94 | 0.95 | 0.94 | 989\n",
    "7 | 0.93 | 0.94 | 0.94 | 1077\n",
    "8 | 0.89 | 0.91 | 0.90 | 985\n",
    "9 | 0.90 | 0.89 | 0.90 | 1018\n",
    "  |      |      |      |\n",
    "avg | 0.92 | 0.92 | 0.92 | 10500\n",
    "\n",
    "<img src=\"img/logreg_real_pred.png\" alt=\"Real vs pred\" style=\"width: 650px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN <a id='chapter-2'></a>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "**KNN** (K nearest neighbors) reprezintă unul din cei mai simpli algoritmi folosiți pentru clasificare/regresie, asta deoarece este *non-parametric*, astfel că datele de antrenare nu sunt folosite pentru a face o *generalizare*, ci pentru a face direct partea de predicție.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Ce înseamnă acest lucru? Algoritmul se uită la o observație din setul de date de test și calculează distanța dintre aceasta și toate observațiile din setul de date de antrenament. La final se aleg cele mai mici k sume și, în cazul clasficării, se alege categoria ca fiind cea care are majoritate între cele k descoperite cu ajutorul algoritmului.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Distanța dintre două imagini poate fi calculată în moduri diferite (dist. Euclidiană, Manhattan etc.), iar noi am folosit-o pe cea Manhattan, deoarece se comportă mai bine pentru date de dimensiuni mari (în cazul nostru dimensiunea este 784).\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Deși **KNN** se descurcă foarte bine la clasificarea imaginilor din setul de date MNIST, **acuratețea fiind de 96.44%**, costul computațional este unul foarte mare. Rularea algoritmului pe MNIST (80% train, 20% test) a durat aproximativ 1 oră si 30 de minute (pentru o abordare iterativă - fiecare intrare de test era tratată separat) și în jur de 11 minute (folosind puterea de calcul a bibliotecii **sklearn**: <a href='http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html'>pairwise distances</a> - ce calculează toate distanțele vectorizat). \n",
    "</p>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM <a id='chapter-3'></a>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Am discutat mai devreme despre faptul că regresiile găsesc un **hiperplan** care aproximează punctele pe care se face antrenamentul unui model. Cu toate acestea, găsirea lui nu înseamnă și faptul că el este cel mai bun. De exemplu, în figura de mai jos sunt reprezentate mai multe hiperplane, fiecare dintre ele făcând corect clasificarea sexelor:\n",
    "</p>\n",
    "<img src=\"img/svm_hiperplane.png\" alt=\"Hiperplane\" style=\"width: 550px;\"/>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Algoritmul **SVM** (Support Vector Machine) caută să găsească hiperplanul care aproximează cel mai bine datele, prin introducerea noțiunii de **margine**: $2\\ast d$, unde $d$ este distanța de la hipreplan la cel mai apropiat punct. Astfel, SVM consideră separația optimă ca fiind cea care maximizează marginea.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru observarea modului în care se comportă acest algoritm la clasificarea cifrelor din MNIST, am folosit un clasificator din biblioteca **sklearn**: <a href='http://scikit-learn.org/stable/modules/svm.html#classification'>SVC</a>, a cărei acuratețe a fost 96.38% pentru datele de antrenament și 94.27% pentru datele de test.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Rețele neuronale complet conectate <a id='chapter-4'></a>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Problema regresiei constă în faptul că nu surprinde deloc non-liniaritățile. Tot ce reușește să facă este să găsească o linie (hiperplan pentru $n > 2$) care să aproximeze cât mai bine punctele (observațiile). Pentru a scăpa de acest inconvenient, am creat o rețea neuronală complet conectată formată dintr-un nivel de intrare (cu 784 neuroni), un nivel ascuns (cu 256 neuroni) și un nivel de ieșire (cu 10 neuroni), care folosește o funcție de activare non-liniară (**ReLU**: $relu(z) = max(0,z)$, **sigmoid**) pentru a produce output-ul fiecărui nivel ascuns și, evident, **softmax** la nivelul de ieșire pentru ca rețeaua să returneze un vector de probabilități cu un număr de componente egal cu numărul de clase. Fiecare componentă a vectorului reprezintă probabilitatea ca imaginea de la intrare să se încadreze în clasa corespunzătoare.\n",
    "</p>\n",
    "\n",
    "<img src=\"img/neural_network.png\" alt=\"Retea neurala\" style=\"width: 550px;\"/>\n",
    "\n",
    "<h6> 1. Forward propagation </h6>\n",
    "\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "    Pentru fiecare nivel, matricea de parametri care trebuie sa fie tunați va fi de dimensiune $(nrUnitsPrev + 1) \\times nrUnitsCurrent$ (+1 pentru **bias**). Astfel, în cazul arhitecturii 784-256-10, au fost folosiți 203,530 parametri, ocupând 0.78MB din memoria totală a calculatorului.\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "    Intrarea pentru primul nivel este chiar setul de date. Acesta reprezintă totodată și ieșirea nivelului. Întotdeauna ieșirea nivelului $i-1$ devine intrare pentru nivelul $i, i = 1 .. n-1$. Astfel, pentru nivelul ascuns se calculează produsul dintre intrare și matricea de parametri - obținând matricea $z$. Intervine însă introducerea non-liniarității care va genera ieșirea (matricea $a$). Asemănător, se calculează matricea $z$ și pentru nivelul de ieșire, după care se aplică **softmax** pentru a genera cele 10 probabilități.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "\n",
    "    $z^{(1)} = XW_0 \\\\\n",
    "    a^{(1)} = f(z^{(1)}) \\\\\n",
    "    z^{(2)} = a^{(1)}W_1 \\\\\n",
    "    a^{(2)} = f(z^{(2)}) = \\hat{y}$\n",
    "    \n",
    "</p>\n",
    "\n",
    "<h6> 2. Backward propagation</h6>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "    Tunarea parametrilor se face tot cu ajutorul metodei **gradientului descendent**.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    $\\frac{\\partial J}{\\partial W_1} = \\frac{1}{m}input^T\\cdot\\delta_2 =  \\frac{1}{m}a^{(1)T}\\cdot(\\hat{y} - y) \\\\ \\\\\n",
    "    \\frac{\\partial J}{\\partial W_0} = \\frac{1}{m}input^T\\cdot\\delta_1 = \\frac{1}{m}X^T\\cdot[(\\delta_2\\cdot W_1^T) \\ast fAct']\\\\\n",
    "    W_1 := W_1 - \\frac{\\alpha}{m}\\frac{\\partial J}{\\partial W_1}\\\\\n",
    "    W_0 := W_0 - \\frac{\\alpha}{m}\\frac{\\partial J}{\\partial W_0}\n",
    "    $\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "    \n",
    "<p style=\"text-align: justify;\">   \n",
    "    Funcția de activare folosită este **ReLU**, a cărei derivată arată astfel:\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    $f'(z)=\\begin{cases} \n",
    "      1 & dacă\\;z > 0 \\\\\n",
    "      0 & altfel\n",
    "   \\end{cases}$\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "   În contrast, graficul derivatei funcției **sigmoid** arată faptul că pe masură ce valoarea sigmoidată este din ce în ce mai mare, derivata în acel punct devine din ce în ce mai mică, ceea ce înseamnă că gradientul va deveni nesemnificativ și astfel, rețeaua nu va fi capabilă să învețe foarte bine:\n",
    "</p>\n",
    "   \n",
    "   <img src=\"img/sigmoid_derivative.png\" alt=\"Sigmoid\" style=\"width: 350px;\"/>\n",
    "   \n",
    "   \n",
    " + <h6>Antrenarea modelului</h6>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Parametrii modelului au fost inițializați folosind metoda **Xavier** (ei sunt aleși de pe o distribuție Gaussiană cu media = 0 și o variație = $\\frac{1}{N}$, $N = $ numărul neuronilor de pe nivelul anterior). Hiperparametrii folosiți pentru antrenament sunt urmatorii: **număr de epoci**: 10; **coeficient de învățare**: 0.001; **dimensiunea unui mini-batch**: 10; **coeficient dropout**: 0.7; **momentum**: 0.9.\n",
    "</p>\n",
    " \n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În timpul antrenamentului au fost înregistrate la fiecare epocă loguri relevante pentru a observa modul în care converge modelul (costul per mini-batch, target real vs target prezis, cost + acuratețe pe seturile de date de antrenament și validare, timpul scurs pe ecopa respectivă):\n",
    "</p>\n",
    "\n",
    "<img src=\"img/nn_logs.png\" alt=\"Logs\" style=\"width: 500px;\"/>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În urma antrenamentului modelului (care a durat aproximativ 185 de secunde), s-au obținut următoarele valori pentru acuratețe:\n",
    "</p>\n",
    "\n",
    "+ pe setul de date folosit pentru antrenament: 98.32%\n",
    "+ pe setul de date de validare: 97.55%\n",
    "+ pe setul de date de test: 97.74%\n",
    "\n",
    "\n",
    "Convergența modelului se poate observa urmărind cele 2 grafice de mai jos:\n",
    "<br>\n",
    "\n",
    "<img align=\"center\" src=\"img/nn_cost_train_val2.png\" alt=\"Cost antrenament, validare\" style=\"width: 1000px;\"/> <br>\n",
    "\n",
    "+ <h6>Rezultatele predicției pe setul de date de test</h6>\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"img/nn_confuzie.png\" alt=\"Matrice confuzie\" style=\"width: 450px;\"/>\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "| Precizie | Recall | F | N Obs\n",
    "--- | --- | --- | --- | ---\n",
    "0 | 0.98 | 0.98 | 0.98 | 1046\n",
    "1 | 0.98 | 0.99 | 0.98 | 1154\n",
    "2 | 0.98 | 0.97 | 0.98 | 1120\n",
    "3 | 0.96 | 0.98 | 0.97 | 1090\n",
    "4 | 0.98 | 0.98 | 0.98 | 1056\n",
    "5 | 0.98 | 0.96 | 0.97 | 965\n",
    "6 | 0.98 | 0.98 | 0.98 | 989\n",
    "7 | 0.97 | 0.97 | 0.97 | 1077\n",
    "8 | 0.97 | 0.97 | 0.97 | 985\n",
    "9 | 0.97 | 0.97 | 0.97 | 1018\n",
    "  |      |      |      |\n",
    "avg | 0.98 | 0.98 | 0.98 | 10500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rețele neuronale de convoluție (CNN) <a id='chapter-5'></a>\n",
    "\n",
    "Rețelele neuronale de convoluție (Convolutional Neural Networks) sunt clasificatori speciali concepuți pentru lucrul cu imagini.\n",
    "\n",
    "În general, CNN au două componente:\n",
    "1. O componentă de extragere a trasăturilor din imagini. Aceasta se compune din mai multe nivele:\n",
    "    + **Nivel de convoluție** <br>\n",
    "    <p style=\"text-align: justify;\">\n",
    "    În cadrul acestuia se realizează convoluția dintre imaginea de intrare și un filtru (matrice $n \\times n, n \\leqslant 5$). Spre deosebire de nivelele din rețelele neuronale clasice, în nivelele de convoluție numărul de conexiuni se reduce la dimensiunea filtrelor utilizate, și nu la cea a imaginii de la intrare. Nivelurile de convoluție produc una sau mai multe *feature maps* (în funcție de numărul de filtre utilizate), imagini care conțin anumite trăsături sau caracteristici ale imaginii de la intrare. Aceste hărți sunt obținute prin plimbarea fiecărui filtru asupra imaginii de intrare (mecanismul **sliding window**).\n",
    "    </p>\n",
    "    <img src=\"img/cnn_convolve.png\" alt=\"Sliding window\" style=\"width: 650px;\"/><br>\n",
    "    \n",
    "    <p style=\"text-align: justify;\">\n",
    "    La antrenarea rețelei, valorile filtrelor se modifică după o logică similară cu cea a rețelelor clasice, ideea fiind de a minimiza eroarea dintre rezultatul de la ieșire dorit și cel obținut efectiv.\n",
    "    </p><br>\n",
    "    \n",
    "    + **Nivel de activare** \n",
    "     <p style=\"text-align: justify;\">\n",
    "    Harțile obținute în urma convoluțiilor sunt supuse unei funcții de activare ce asigură comportamentul non-liniar al rețelei. Ca funcție de activare, de cele mai multe ori se folosește **ReLU**.\n",
    "    </p><br>\n",
    "    + **Nivel de agregare (pooling)**\n",
    "    <p style=\"text-align: justify;\">\n",
    "    În cadrul acestui nivel se realizează o reducere a dimensiunilor hărților de activare. Astfel, operația de pooling 2x2 aplicată pe o hartă de dimensiune 28x28 generează o hartă de dimensiune 14x14. Reducerea dimensiunii pentru fiecare grup 2x2 de pixeli se poate realiza prin mai multe metode: de exemplu, se determină maximul dintre cei 2x2 pixeli (max pooling). \n",
    "    </p><br>\n",
    "    \n",
    "2. O componentă complet conectată (fully-connected), în cadrul căreia se realizează clasificarea propriu-zisă. Această componentă este o rețea neuronală clasică, la intrarea căreia se furnizează *feature map-urile* și la ieșirea căreia se aplică funcția de activare **softmax**, pentru a încadra imaginea în clasa corespunzătoare.\n",
    "\n",
    "+ **Antrenarea modelului**\n",
    "\n",
    "    Arhitectura aleasă pentru rețeaua ce clasifică imaginile din MNIST este următoarea:<br>\n",
    "    - *INPUT* [28x28x1] - reprezintă pixelii imaginii: 28 pixeli înalțime, 28 pixeli lățime, un canal de culoare (\"grayscale\")\n",
    "    - *CONV* - este responsabil cu crearea hărților despre care s-a discutat: am folosit 32 de filtre de 3x3 care se plimbă cu pas=1. Se folosește și o tehnică de bordare a imaginii cu 0-uri, astfel încât harta să aibă aceeași dimensiune. Volumul ce trebuie procesat este acum [28x28x32]\n",
    "    - *RELU* - se aplică funcția de activare ReLU. Volumul rămâne același.\n",
    "    - *MAXPOOL* - \"downsampling\"; fereastra de 2x2 se plimbă cu pas=2.\n",
    "    - *CONV* - crearea unor hărți care să surprindă trăsături și mai abstracte. Am folosit 64 de filtre de 3x3 care se plimbă cu pas=1. Dimensiumea volumului devine [14x14x64]\n",
    "    - *RELU* - se aplică funcția de activare ReLU.\n",
    "    - *MAXPOOL* - din nou se face același \"downsampling\" pe noile hărți\n",
    "    - *FC* - se creează o rețea neuronală cu 3 niveluri: [input, $7\\ast7\\ast64$ neuroni]; [hidden, 1000 neuroni, act=ReLU]; [output, 10 neuroni, act=softmax].\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Modelul s-a descurcat semnificativ mai bine decât o rețea neuronală complet conectată, obținând următoarele rezultate dupa antrenarea și testarea modelului pe MNIST:\n",
    "  - Acuratețe: train (99.49%), validare (98.87%), test (99.06%)\n",
    "  - Timp total de rulare: 11 minute 08 secunde (pentru 3 epoci)\n",
    "</p>\n",
    " \n",
    "\n",
    "<br><br>\n",
    "<p style=\"text-align: justify;\">\n",
    "S-au folosit tehnici de afișare a câtorva filtre folosite pentru a extrage trăsăturilor imaginilor. La finalul antrenamentului, ele arătă în felul următor:\n",
    "</p>\n",
    "<img src=\"img/cnn_filters.png\" alt=\"Filtre\" style=\"width: 1350px;\"/>\n",
    "\n",
    "\n",
    "+ **Inferența pe scene de dimensiuni variate**\n",
    "\n",
    "    Deși am găsit o modalitate de recunoaștere a trăsăturilor din imagini, încă nu se poate face inferența pe scene cu dimensiuni diferite de 28x28, deoarece prin max-pooling se face doar un 'downsampling' al hărților, iar numărul de neuroni de pe layer-ul de intrare al componentei *fully-connected* va depinde de dimensiunea imaginilor pe care s-a făcut antrenamentul. Astfel, pentru ca rețeaua să poată face inferența pe orice scenă după ce a fost antrenată, am hotărât ca după ultimul nivel de convoluție să folosim **global max pooling** - alegem valoarea maximă din fiecare hartă. Este evident că vom avea un număr egal de hărți cu cel al filtrelor folosite pe ultimul nivel de convoluție și astfel numărul neuronilor de pe layer-ul de intrare al componentei FC va fi dependent doar de arhitectura aleasă.\n",
    "\n",
    "    Arhitectura rețelei devine: *INPUT* [28x28x1] - *CONV* [32 filtre de dimensiune 3x3] - *ReLU* [asupra volumului de dimensiune 28x28x32] - *CONV* [256 filtre de dimensiune 3x3] - *ReLU* [asupra volumului de dimensiune 28x28x256] - *GMP* - *FC* [rețea neuronală cu 2 niveluri: (input, 256 neuroni); (output, 10 neuroni, act=softmax)]. Cu ajutorul acesteia, s-a obținut o acuratețe de peste 96% pe date de test de orice dimensiune (scene care arată precum cele prezentate în capitolul următor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fereastra glisantă <a id='chapter-6'></a>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru acest experiment, am înglobat toate cele 10500 de imagini din setul de date de test în scene de diverse dimensiuni (40x80, 50x40, 100x50), în poziții aleatoare. Colajul de mai jos conține 6 imagini din MNIST puse în cele 3 scene:\n",
    "</p>\n",
    "\n",
    "<img src=\"img/scene.png\" alt=\"Filtre\" style=\"width: 850px;\"/>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "În continuare, am implementat mecanismul **sliding window**, plimbând o fereastră de 28x28 pe fiecare scenă. Scopul a fost găsirea target-ului, cât și poziția exactă a cifrei în scenă. Vom analiza rezultatele obținute prin utilizarea fiecărui model:\n",
    "</p>\n",
    "\n",
    "+ **Regresie logistică**\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Vom analiza 2 scene de dimensiune 40x80, una în care modelul nostru a identificat corect cifra poziționată în scenă, iar alta în care acesta a generat o predicție falsă.\n",
    "</p>\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/1_40x80.png' alt='missing' style=\"width: 750px;\"/>\n",
    "    <figcaption><center><b>Scenă de 40x80 cu cifra 1 poziționată la (2, 26)</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Modelul antrenat pe datele din MNIST a identificat corect cifra 1 din scena de mai sus, cu o siguranță de 98,97%. Fereastra de siguranță maximă s-a găsit la poziția (4, 26), aflându-se la o distanță rezonabilă de poziția corectă.\n",
    "Siguranța de la fereastra de pe poziția exactă a fost 97,48%, diferența de probabilitate între cele 2 poziții fiind de sub 1,5%.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Acum ne vom orienta atenția către vizualizarea matricilor de activare, între ferestre (prezisă și corectă) și regresorii asociați cifrei prezise, respectiv cifrei corecte</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/1_FC.png' alt='missing' style=\"width: 750px;\"/>\n",
    "    <figcaption><center><b>Matrice de activare pentru fereastra de pe poziția corectă</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/1_FI.png' alt='missing' style=\"width: 950px;\"/>\n",
    "    <figcaption><center><b>Matricile de activare pentru fereastra de pe poziția prezisă</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/9_40x80.png' alt='missing' style=\"width: 750px;\"/>\n",
    "    <figcaption><center><b>Scenă de 40x80 cu cifra 9 poziționată la (10, 4)</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Modelul nostru a identificat în fereastra de la poziția (6, 1), cu siguranța maximă de 98,77%, cifra 6. Probabilitatea obținută pe fereastra de la poziția exactă a fost de 80,15%, prezicând corect cifra 9, dar cu o siguranță mult mai mică față de cifra 6 de la poziția (6,1).\n",
    "</p>\n",
    "\n",
    "Urmează să vizualizăm matricile de activare.\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/9_FC.png' alt='missing' style=\"width: 750px;\"/>\n",
    "    <figcaption><center><b>Matrice de activare pentru fereastra de pe poziția corectă</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<br>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/9_FI.png' alt='missing' style=\"width: 950px;\"/>\n",
    "    <figcaption><center><b>Matricile de activare pentru fereastra de pe poziția prezisă</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<hr><br>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru a ne da seama de acuratețea modelului, am lăsat algoritmul să ruleze pe toate cele 3 seturi de date. Nu vom oferi o acuratețe clasică în procente, ci un număr de scene prezise corect sau greșit într-un anumit mod, pe fiecare set de scene în parte. Metrica folosită pentru fiecare set de scene este: în câte scene a identificat corect atât cifra, cât și poziția acesteia, în câte scene a identificat corect doar cifra și în câte a greșit. Trebuie menționat că în verificarea poziției s-a ținut cont de un epsilon de 2 pixeli, în toate direcțiile. \\\n",
    "</p>\n",
    "\n",
    "```C++\n",
    "Rezultatele rulării regresiei logistice:\n",
    "[2017.09.26-12:59:17] Scenes of sz 40x80 - 427.57s -  corrects=1883, partially_wrongs=2054, wrongs=6563\n",
    "[2017.09.26-13:02:19] Scenes of sz 50x40 - 182.16s - corrects=2346, partially_wrongs=2166, wrongs=5988\n",
    "[2017.09.26-13:19:30] Scenes of sz 100x50 - 1031.35s - corrects=1524, partially_wrongs=1852, wrongs=7124\n",
    "```\n",
    "\n",
    "+ **Rețele neuronale FC**\n",
    "\n",
    "```C++\n",
    "Rezultatele rulării rețelei neuronale:\n",
    "[2017.09.26-01:25:53] Scenes of sz 40x80 - 2653.00s - corrects=6241, partially_wrongs=1684, wrongs=2575\n",
    "[2017.09.26-01:45:04] Scenes of sz 50x40 - 1150.68s - corrects=6174, partially_wrongs=1710, wrongs=2616\n",
    "[2017.09.26-03:22:50] Scenes of sz 100x50 - 5865.57s - corrects=5359, partially_wrongs=1665, wrongs=3476\n",
    "```\n",
    "\n",
    "+ **CNN**\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru a observa mai bine cum se comportă modelul rezultat în urma antrenării folosind CNN, am folosit OpenCV pentru a vizualiza felul în care fereastra este baleată asupra scenei. Totodată, în momentul în care fereastra ajunge să fie deasupra unor pixeli activați, se face și inferența - prezicerea target-ului și probabilitatea cu care modelul prezice. Am ales aleator 10 scene din cele procesate pentru testare și pentru fiecare am desenat fereastra pentru care s-a obținut probabilitatea maximă.\n",
    "</p>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/collage.png' alt='missing' style=\"width: 750px;\"/>\n",
    "    <figcaption><center><b>Găsirea target-ului la într-o scenă</b></center></figcaption>\n",
    "</figure>\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Se observă faptul că modelul nostru nu numai că își dă seama că într-o scenă este desenată o anumită cifră, ci detectează și locul unde ea se află. Vom vedea în ultima parte a raportului felul în care modelul se descurcă pe o scenă cu mai multe cifre desenate și tot acolo vom analiza și pozițiile la care sunt găsite.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comportament CNN pe scene care înglobează mai mult de o imagine <a id='chapter-7'></a>\n",
    "\n",
    "+ **Cifre de dimensiuni egale (28x28)**\n",
    "\n",
    "Am creat o scenă de dimensiune 300x300, pe care am desenat 15 cifre alese aleator din setul de date de test. Cifrele au fost dispuse astfel:\n",
    "\n",
    "```C++\n",
    "[{'object': 6, 'pos_left_up': (3, 4)},\n",
    " {'object': 8, 'pos_left_up': (15, 72)},\n",
    " {'object': 2, 'pos_left_up': (0, 158)},\n",
    " {'object': 7, 'pos_left_up': (80, 250)},\n",
    " {'object': 3, 'pos_left_up': (90, 43)},\n",
    " {'object': 2, 'pos_left_up': (180, 10)},\n",
    " {'object': 3, 'pos_left_up': (260, 20)},\n",
    " {'object': 1, 'pos_left_up': (200, 100)},\n",
    " {'object': 4, 'pos_left_up': (110, 165)},\n",
    " {'object': 3, 'pos_left_up': (220, 220)},\n",
    " {'object': 3, 'pos_left_up': (270, 150)},\n",
    " {'object': 5, 'pos_left_up': (90, 77)},\n",
    " {'object': 0, 'pos_left_up': (10, 260)},\n",
    " {'object': 8, 'pos_left_up': (150, 220)},\n",
    " {'object': 1, 'pos_left_up': (30, 170)}]\n",
    "```\n",
    "\n",
    "Am aplicat algoritmul care plimbă fereastra asupra întregii scene (din 2 în 2 pixeli), face inferența utilizând modelul antrenat cu CNN și am obținut următorul rezultat:\n",
    "\n",
    "```C++\n",
    "[{'object': 6, 'pos_left_up': (4, 0), 'probability': 100%},\n",
    " {'object': 8, 'pos_left_up': (16, 78), 'probability': 99.91%},\n",
    " {'object': 2, 'pos_left_up': (2, 154), 'probability': 100%},\n",
    " {'object': 7, 'pos_left_up': (80, 254), 'probability': 99.26%},\n",
    " {'object': 3, 'pos_left_up': (90, 42), 'probability': 99.95%},\n",
    " {'object': 2, 'pos_left_up': (182, 8), 'probability': 99.99%},\n",
    " {'object': 3, 'pos_left_up': (258, 14), 'probability': 99.97%},\n",
    " {'object': 1, 'pos_left_up': (202, 94), 'probability': 100%},\n",
    " {'object': 4, 'pos_left_up': (110, 164), 'probability': 99.92%},\n",
    " {'object': 3, 'pos_left_up': (220, 226), 'probability': 99.98%},\n",
    " {'object': 3, 'pos_left_up': (270, 144), 'probability': 100%},\n",
    " {'object': 5, 'pos_left_up': (88, 70), 'probability': 99.79%},\n",
    " {'object': 0, 'pos_left_up': (10, 266), 'probability': 98.58%},\n",
    " {'object': 8, 'pos_left_up': (150, 218), 'probability': 99.88%},\n",
    " {'object': 1, 'pos_left_up': (32, 162), 'probability': 100%}]\n",
    "```\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Pentru validarea rezultatului de mai sus, am folosit OpenCV, ce ne ajută să desenăm ferestrele exact la pozițiile menționate. Se observă clar că modelul găsește cifrele în vecinătatea pozițiilor care descriu imaginile din MNIST **centrate**, astfel încât putem trage concluzia că modelul are capacitatea de a distinge trăsături specifice unei imagini.\n",
    "</p><br>\n",
    "\n",
    "<figure>\n",
    "    <img src='img/scene_inference.png' alt='missing' style=\"width: 500px;\"/>\n",
    "    <figcaption><center><b>Inferența făcută pe o scenă cu mai multe obiecte (cifre)</b></center></figcaption>\n",
    "</figure>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
