{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def guess_encoding(csv_file):\n",
    "    import io\n",
    "    import locale\n",
    "    with io.open(csv_file, \"rb\") as f:\n",
    "        data = f.read(5)\n",
    "    if data.startswith(b\"\\xEF\\xBB\\xBF\"):  # UTF-8 with a \"BOM\"\n",
    "        return \"utf-8-sig\"\n",
    "    elif data.startswith(b\"\\xFF\\xFE\") or data.startswith(b\"\\xFE\\xFF\"):\n",
    "        return \"utf-16\"\n",
    "    else:  # in Windows, guessing utf-8 doesn't work, so we have to try\n",
    "        try:\n",
    "            with io.open(csv_file, encoding=\"utf-8\") as f:\n",
    "                preview = f.read(222222)\n",
    "                return \"utf-8\"\n",
    "        except:\n",
    "            return locale.getdefaultlocale()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(embeddings_filename):\n",
    "    embeddings_fp = open(embeddings_filename, encoding = guess_encoding(embeddings_file))\n",
    "    file_content = embeddings_fp.readlines()\n",
    "    file_content = [line.split(' ') for line in file_content]\n",
    "    file_content = [ [elem[0]] + list(map(float, elem[1:])) for elem in file_content]\n",
    "    \n",
    "    embeddings_colnames = ['E_' + str(i) for i in range(len(file_content[0]) - 1)]\n",
    "    embeddings_df = pd.DataFrame(file_content, columns = ['Word'] + embeddings_colnames)\n",
    "    \n",
    "    return embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_file = \"D:/Google Drive/_cloudifier_data/09_tests/_glove_words/glove.6B.50d.txt\"\n",
    "embeddings_df = preprocess_data(embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordEmbeddingsExperiment():\n",
    "    def __init__(self, embeddings_df):\n",
    "        self.embeddings_df = embeddings_df\n",
    "        self.all_words = embeddings_df['Word'].values\n",
    "        self.np_embeddings = embeddings_df.iloc[:, 1:].values\n",
    "        self.words_by_pos = dict(zip(self.all_words, range(0, len(self.all_words))))\n",
    "        \n",
    "    def _print_stats(self, word, word_vec, k):\n",
    "                \n",
    "        dist_word = pairwise_distances(word_vec.reshape(1,-1), self.np_embeddings).flatten()\n",
    "       \n",
    "        print(\"Top {} closest words for {}\".format(k, word))\n",
    "        top_k_indexes = np.argsort(dist_word1)[1 : (k + 1)]\n",
    "        print(\"{}\".format(np.take(self.all_words, top_k_indexes)))\n",
    "        print()\n",
    "        \n",
    "    def word_simple_op(self, word1, word2, simple_op):\n",
    "        word1_vec = self.np_embeddings[self.words_by_pos[word1]]\n",
    "        word2_vec = self.np_embeddings[self.words_by_pos[word2]]\n",
    "        \n",
    "        words_dist = np.sqrt(np.sum((word1_vec - word2_vec)**2))\n",
    "        print(\"Distance between {} and {} is {}\".format(word1, word2, words_dist))\n",
    "        \n",
    "        self._print_stats(word1, word1_vec, 20)\n",
    "        self._print_stats(word2, word2_vec, 20)\n",
    "        \n",
    "        res_vec = simple_op(word1_vec, word2_vec)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        if simple_op == operator.sub:\n",
    "            k = 10\n",
    "            print(\"Top {} closest words for difference\".format(k*2))\n",
    "            res_diff = pairwise_distances(diff_vec.reshape(1,-1), self.np_embeddings).flatten()\n",
    "        \n",
    "            sort_indexes = np.argsort(dist_diff)\n",
    "            top_k_indexes_minus = sort_indexes[:k]\n",
    "            top_k_indexes_plus = sort_indexes[-(k+1):]\n",
    "            print(\"{}\".format(np.take(self.all_words, top_k_indexes_minus)))\n",
    "            print(\"{}\".format(np.take(self.all_words, top_k_indexes_plus)))\n",
    "        else:\n",
    "            self._print_stats(\"difference\", word)\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "    def word_avg(self, words_list):\n",
    "\n",
    "        words_vec = [self.np_embeddings[self.words_by_pos[word]] for word in  words_list]\n",
    "        \n",
    "        avg_vec = np.average(words_vec, axis = 0)\n",
    "        \n",
    "        k = 20\n",
    "        print(\"Top {} closest words for average of {}\".format(k, words_list))\n",
    "        avg_diff = pairwise_distances(avg_vec.reshape(1,-1), self.np_embeddings).flatten()\n",
    "        \n",
    "        top_k_indexes = np.argsort(avg_diff)[1 : (k + 1)]\n",
    "        print(\"{}\".format(np.take(self.all_words, top_k_indexes)))\n",
    "        \n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between man and gender is 6.838671318666295\n",
      "Top 20 closest words for man\n",
      "['woman' 'another' 'boy' 'one' 'old' 'turned' 'whose' 'himself' 'who'\n",
      " 'friend' 'him' 'gets' 'a' 'blind' 'once' 'young' 'person' 'victim' 'his'\n",
      " 'thought']\n",
      "\n",
      "Top 20 closest words for gender\n",
      "['ethnicity' 'orientation' 'racial' 'mainstreaming' 'societal' 'defining'\n",
      " 'preferences' 'sexes' 'bias' 'irrespective' 'regardless' 'attitudes'\n",
      " 'equality' 'workplace' 'define' 'discrimination' 'makeup' 'defines'\n",
      " 'demographics' 'sexuality']\n",
      "\n",
      "Top 20 closest words for difference\n",
      "['landed' 'roger' 'nicknamed' 'cole' 'fisherman' 'blew' 'barge' 'chased'\n",
      " 'captain' 'crewman']\n",
      "['www.star' 'story3d' 'officership' '20003' 'daybook' 'non-obligatory'\n",
      " 'afptv' '202-383-7824' 'eighteens' '25-64' 'non-families']\n",
      "\n",
      "\n",
      "Distance between day and sun is 4.95315822564458\n",
      "Top 20 closest words for day\n",
      "['days' 'next' 'coming' 'weekend' 'came' 'week' 'here' 'night' 'time'\n",
      " 'morning' 'on' 'weeks' 'last' 'before' 'took' 'month' 'start' 'starts'\n",
      " 'afternoon' 'went']\n",
      "\n",
      "Top 20 closest words for sun\n",
      "['sky' 'cloud' 'moon' 'bright' 'sunshine' 'hung' 'light' 'blue' 'o' 'today'\n",
      " 'dappled' '.' 'spring' 'lit' 'fan' 'times' 'hot' 'cool' 'touch' 'close']\n",
      "\n",
      "Top 20 closest words for difference\n",
      "['contemplating' 'overdue' 'delaying' 'cutback' '30-270' 'misses' 'barring'\n",
      " 'embarking' 'contemplated' 'entailed']\n",
      "['dehl' '25-64' 'computerologist' 'http://www.nasdaq.com' '20003'\n",
      " 'drbombay' 'non-institutionalized' 'officership' 'www.star' 'non-families'\n",
      " '202-383-7824']\n",
      "\n",
      "\n",
      "Distance between man and sex is 4.886782479545718\n",
      "Top 20 closest words for man\n",
      "['woman' 'another' 'boy' 'one' 'old' 'turned' 'whose' 'himself' 'who'\n",
      " 'friend' 'him' 'gets' 'a' 'blind' 'once' 'young' 'person' 'victim' 'his'\n",
      " 'thought']\n",
      "\n",
      "Top 20 closest words for sex\n",
      "['sexual' 'child' 'abuse' 'homosexual' 'adult' 'teen' 'gay' 'teenagers'\n",
      " 'sexuality' 'pornography' 'prostitution' 'teens' 'behavior' 'lesbian'\n",
      " 'rape' 'minors' 'prostitute' 'parents' 'smoking' 'instance']\n",
      "\n",
      "Top 20 closest words for difference\n",
      "['bunker' 'nicknamed' 'crewman' 'scot' 'gunner' 'horseman' 'atop' 'floored'\n",
      " 'ranger' 'blasted']\n",
      "['eighteens' 'daybook' 'officership' 'http://www.nyse.com' '212-556-4204'\n",
      " 'www.star' 'non-obligatory' 'afptv' '25-64' 'non-families' '202-383-7824']\n",
      "\n",
      "\n",
      "Top 20 closest words for average of ['day', 'monday', 'weekend', 'today']\n",
      "['week' 'weekend' 'days' 'friday' 'sunday' 'here' 'thursday' 'last' 'came'\n",
      " 'today' 'monday' 'next' 'tuesday' 'wednesday' 'on' 'month' 'saturday'\n",
      " 'coming' 'morning' 'afternoon']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = WordEmbeddingsExperiment(embeddings_df)\n",
    "experiment.word_diff('man', 'gender')\n",
    "experiment.word_diff('day', 'sun')\n",
    "experiment.word_diff('man', 'sex')\n",
    "\n",
    "experiment.word_avg(['day', 'monday', 'weekend', 'today'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
