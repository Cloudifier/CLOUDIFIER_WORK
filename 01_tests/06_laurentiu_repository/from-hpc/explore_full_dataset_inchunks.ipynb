{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from IPython.display import display, HTML\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.sparse import save_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLogger:\n",
    "    def __init__(self):\n",
    "        self.last_time = time()\n",
    "        self.c_time = time()\n",
    "  \n",
    "    def VerboseLog(self, _str, show_time = False):\n",
    "        self.last_time = self.c_time\n",
    "        self.c_time = time()\n",
    "        if show_time:\n",
    "            _str += \" [{:.2f}s]\".format(self.c_time-self.last_time)\n",
    "        print(_str, flush = True)\n",
    "  \n",
    "    def log(self, _str, show_time = False):\n",
    "        self.last_time = self.c_time\n",
    "        self.c_time = time()\n",
    "        if show_time:\n",
    "            _str += \" [{:.2f}s]\".format(self.c_time-self.last_time)    \n",
    "        print(_str, flush = True)\n",
    "\n",
    "logger = SimpleLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_df(df, fname):\n",
    "    import os\n",
    "    if not os.path.isfile(fname):\n",
    "        df.to_csv(fname)\n",
    "    else:\n",
    "        df.to_csv(fname, mode = 'a', header = False)\n",
    "    \n",
    "    return\n",
    "\n",
    "def add_vect_to_mco(mco, vect, window = 2, max_count = 64000):\n",
    "    DEBUG = False\n",
    "    for i, prod_id in enumerate(vect):\n",
    "        nr_left_prods = min(vect[:i].shape[0], window)\n",
    "        nr_right_prods = min(vect[i+1:].shape[0], window)\n",
    "        for j in range(nr_left_prods):\n",
    "            l_ind = i - (j + 1)\n",
    "            l_prod = vect[l_ind]\n",
    "            if l_prod != prod_id:\n",
    "                current_mco_val = mco[prod_id, l_prod]\n",
    "                mco[prod_id, l_prod] = min(current_mco_val + 1 / (2 ** (j + 1)), max_count)\n",
    "                if DEBUG:\n",
    "                    print('MCO[{}][{}] = {}'.format(prod_id, l_prod, mco[prod_id, l_prod]))\n",
    "\n",
    "        for j in range(nr_right_prods):\n",
    "            r_ind = i + j + 1\n",
    "            r_prod = vect[r_ind]\n",
    "            if r_prod != prod_id:\n",
    "                current_mco_val = mco[prod_id, r_prod]\n",
    "                mco[prod_id, r_prod] = min(current_mco_val + 1 / (2 ** (j + 1)), max_count)\n",
    "                if DEBUG:\n",
    "                    print('MCO[{}][{}] = {}'.format(prod_id, r_prod, mco[prod_id, r_prod]))\n",
    "\n",
    "    return mco           \n",
    "\n",
    "#unique_trans_grouped = None\n",
    "def process_chunk(df_chunk, tran_field, tran_det_field, mco, prod_name_field):\n",
    "    #global unique_trans_grouped\n",
    "    import itertools\n",
    "    \n",
    "    start = time()\n",
    "    unique_trans_grouped = df_chunk.groupby(tran_field).apply(lambda x: [x[prod_name_field].values, x[tran_det_field].values])\n",
    "    unique_trans_grouped = np.array(unique_trans_grouped)\n",
    "    logger.log('  Groupby operation finished in {:.2f}s'.format(time() - start))\n",
    "    \n",
    "    start = time()\n",
    "    for i, l in enumerate(unique_trans_grouped):\n",
    "        real_order_mask = np.argsort(l[1])\n",
    "        market_basket = l[0][real_order_mask]\n",
    "        market_basket = np.array([k for k,g in itertools.groupby(market_basket)]) # collapse adjacent identic elements\n",
    "        if market_basket.shape[0] == 1:\n",
    "            continue\n",
    "            \n",
    "        mco = add_vect_to_mco(mco, market_basket)\n",
    "\n",
    "    logger.log('  Unique market baskets processed in {:.2f}s'.format(time() - start))\n",
    "    \n",
    "    return mco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mco ...\n",
      "Created mco. [0.02s]\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['TRAN_ID', 'TRAN_DET_ID', 'SITE_ID', 'TIMESTAMP', 'NEW_ID']\n",
    "all_cols = ['TRAN_ID', 'TRAN_DET_ID', 'SITE_ID', 'CUST_ID', 'ITEM_ID', 'QTY', 'AMOUNT', 'TIMESTAMP', 'NEW_ID']\n",
    "chunksize = 10e6\n",
    "nr_products = 28377\n",
    "\n",
    "reader = pd.read_csv('full_dataset_transactions.csv',\n",
    "                     names = all_cols,\n",
    "                     chunksize = chunksize)\n",
    "\n",
    "logger.log('Creating mco ...')\n",
    "mco = np.zeros((nr_products + 1, nr_products + 1), dtype = np.float32)\n",
    "logger.log('Created mco.', show_time = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing batch 1 with 10,000,000 entries...\n",
      "Done preprocessing batch. [53.67s]\n",
      "Processing the batch #1 ...\n",
      "  Groupby operation finished in 372.04s\n",
      "  Unique market baskets processed in 91.18s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 2 with 10,000,000 entries...\n",
      "Done preprocessing batch. [56.02s]\n",
      "Processing the batch #2 ...\n",
      "  Groupby operation finished in 390.13s\n",
      "  Unique market baskets processed in 92.30s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 3 with 10,000,000 entries...\n",
      "Done preprocessing batch. [56.66s]\n",
      "Processing the batch #3 ...\n",
      "  Groupby operation finished in 381.90s\n",
      "  Unique market baskets processed in 97.57s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 4 with 10,000,000 entries...\n",
      "Done preprocessing batch. [55.09s]\n",
      "Processing the batch #4 ...\n",
      "  Groupby operation finished in 386.18s\n",
      "  Unique market baskets processed in 95.45s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 5 with 10,000,000 entries...\n",
      "Done preprocessing batch. [55.03s]\n",
      "Processing the batch #5 ...\n",
      "  Groupby operation finished in 374.67s\n",
      "  Unique market baskets processed in 95.17s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 6 with 10,000,000 entries...\n",
      "Done preprocessing batch. [54.24s]\n",
      "Processing the batch #6 ...\n",
      "  Groupby operation finished in 385.53s\n",
      "  Unique market baskets processed in 95.45s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 7 with 10,000,000 entries...\n",
      "Done preprocessing batch. [55.11s]\n",
      "Processing the batch #7 ...\n",
      "  Groupby operation finished in 391.98s\n",
      "  Unique market baskets processed in 92.06s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 8 with 10,000,000 entries...\n",
      "Done preprocessing batch. [54.81s]\n",
      "Processing the batch #8 ...\n",
      "  Groupby operation finished in 374.81s\n",
      "  Unique market baskets processed in 94.82s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 9 with 10,000,000 entries...\n",
      "Done preprocessing batch. [56.30s]\n",
      "Processing the batch #9 ...\n",
      "  Groupby operation finished in 379.61s\n",
      "  Unique market baskets processed in 106.43s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 10 with 10,000,000 entries...\n",
      "Done preprocessing batch. [57.50s]\n",
      "Processing the batch #10 ...\n",
      "  Groupby operation finished in 381.60s\n",
      "  Unique market baskets processed in 92.61s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 11 with 10,000,000 entries...\n",
      "Done preprocessing batch. [53.57s]\n",
      "Processing the batch #11 ...\n",
      "  Groupby operation finished in 398.85s\n",
      "  Unique market baskets processed in 104.19s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 12 with 10,000,000 entries...\n",
      "Done preprocessing batch. [53.83s]\n",
      "Processing the batch #12 ...\n",
      "  Groupby operation finished in 376.85s\n",
      "  Unique market baskets processed in 104.39s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 13 with 10,000,000 entries...\n",
      "Done preprocessing batch. [57.16s]\n",
      "Processing the batch #13 ...\n",
      "  Groupby operation finished in 356.37s\n",
      "  Unique market baskets processed in 97.00s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 14 with 10,000,000 entries...\n",
      "Done preprocessing batch. [54.82s]\n",
      "Processing the batch #14 ...\n",
      "  Groupby operation finished in 354.90s\n",
      "  Unique market baskets processed in 108.17s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 15 with 10,000,000 entries...\n",
      "Done preprocessing batch. [56.34s]\n",
      "Processing the batch #15 ...\n",
      "  Groupby operation finished in 373.48s\n",
      "  Unique market baskets processed in 94.83s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 16 with 10,000,000 entries...\n",
      "Done preprocessing batch. [56.14s]\n",
      "Processing the batch #16 ...\n",
      "  Groupby operation finished in 365.35s\n",
      "  Unique market baskets processed in 95.34s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 17 with 10,000,000 entries...\n",
      "Done preprocessing batch. [57.40s]\n",
      "Processing the batch #17 ...\n",
      "  Groupby operation finished in 366.65s\n",
      "  Unique market baskets processed in 97.52s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 18 with 10,000,000 entries...\n",
      "Done preprocessing batch. [58.50s]\n",
      "Processing the batch #18 ...\n",
      "  Groupby operation finished in 414.15s\n",
      "  Unique market baskets processed in 189.67s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 19 with 10,000,000 entries...\n",
      "Done preprocessing batch. [57.54s]\n",
      "Processing the batch #19 ...\n",
      "  Groupby operation finished in 394.03s\n",
      "  Unique market baskets processed in 103.84s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 20 with 10,000,000 entries...\n",
      "Done preprocessing batch. [57.94s]\n",
      "Processing the batch #20 ...\n",
      "  Groupby operation finished in 410.26s\n",
      "  Unique market baskets processed in 99.34s\n",
      "Done processing the batch.\n",
      "Preprocessing batch 21 with 5,661,770 entries...\n",
      "Done preprocessing batch. [32.54s]\n",
      "Processing the batch #21 ...\n",
      "  Groupby operation finished in 216.21s\n",
      "  Unique market baskets processed in 51.24s\n",
      "Done processing the batch.\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(reader):\n",
    "    logger.log('Preprocessing batch {} with {:,} entries...'.format(i+1, batch.shape[0]))\n",
    "    df = pd.DataFrame(batch[keep_cols])\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    df.loc[:, 'FTRAN'] = df['SITE_ID'].astype(str) + df['TRAN_ID'].astype(str)\n",
    "    df.drop(['TRAN_ID', 'SITE_ID'], axis = 1, inplace = True)\n",
    "    logger.log('Done preprocessing batch.', show_time = True)\n",
    "    logger.log('Processing the batch #{} ...'.format(i+1))\n",
    "    mco = process_chunk(df, 'FTRAN', 'TRAN_DET_ID', mco, 'NEW_ID')\n",
    "    logger.log('Done processing the batch.')\n",
    "\n",
    "mco.dump('mco_f32.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sanity check </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO THESE OPERATIONS WITH chunksize=2e3 and DEBUG set to True in add_vect_to_mco\n",
    "\n",
    "df_test = pd.DataFrame(reader.get_chunk()[keep_cols])\n",
    "df_test.loc[:, 'FTRAN'] = df_test['SITE_ID'].astype(str) + df_test['TRAN_ID'].astype(str)\n",
    "df_test.drop(['TRAN_ID', 'SITE_ID', 'TIMESTAMP'], axis = 1, inplace = True)\n",
    "\n",
    "logger.log('Start grouping {:,} entries ... '.format(df_test.shape[0]))\n",
    "unique_trans_grouped = df_test.groupby('FTRAN').apply(lambda x: [x['NEW_ID'].values, x['TRAN_DET_ID'].values])\n",
    "logger.log('Finished grouping.', show_time = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO THESE OPERATIONS WITH chunksize=2e3 and DEBUG set to True in add_vect_to_mco\n",
    "\n",
    "mco = np.zeros((nr_products + 10, nr_products + 10), dtype = np.float16)\n",
    "tqdm_works=True\n",
    "import itertools\n",
    "for i, l in enumerate(unique_trans_grouped):\n",
    "    real_order_mask = np.argsort(l[1])\n",
    "    market_basket = l[0][real_order_mask]\n",
    "    market_basket = np.array([k for k,g in itertools.groupby(market_basket)]) # collapse adjacent identic elements\n",
    "    if market_basket.shape[0] == 1:\n",
    "        continue\n",
    "\n",
    "    print(market_basket)\n",
    "        \n",
    "    mco = add_vect_to_mco(mco, market_basket)\n",
    "    if tqdm_works:\n",
    "        one_percent = int(unique_trans_grouped.shape[0] * 0.01)\n",
    "        if i % one_percent == 0:\n",
    "            logger.log('  Processed {:.2f}%.'.format((i / unique_trans_grouped.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Sanity check nr. 2 - for the first 10M chunk </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "unique_trans_grouped = df.groupby('FTRAN').apply(lambda x: [x['NEW_ID'].values, x['TRAN_DET_ID'].values])\n",
    "unique_trans_grouped = np.array(unique_trans_grouped)\n",
    "logger.log('  Groupby operation finished in {:.2f}s'.format(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mco[1387][397])\n",
    "print(mco[1387][342])\n",
    "print(mco[1387][62])\n",
    "print(mco[1387][2249])\n",
    "print(mco[1387][183])\n",
    "print(mco[1387][1300])\n",
    "print(mco[1387][43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "d = []\n",
    "for i, l in enumerate(unique_trans_grouped):\n",
    "    real_order_mask = np.argsort(l[1])\n",
    "    market_basket = l[0][real_order_mask]\n",
    "    market_basket = np.array([k for k,g in itertools.groupby(market_basket)]) # collapse adjacent identic elements\n",
    "    if market_basket.shape[0] == 1:\n",
    "        continue\n",
    "        \n",
    "    if (1387 in market_basket) and (187 in market_basket):\n",
    "        d.append(market_basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_mco = np.zeros((29000,29000), dtype = np.float16)\n",
    "for v in d:\n",
    "    sc_mco = add_vect_to_mco(sc_mco, v)\n",
    "print(sc_mco[5,12])\n",
    "print(sc_mco[12,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "d = []\n",
    "for i, l in enumerate(unique_trans_grouped):\n",
    "    real_order_mask = np.argsort(l[1])\n",
    "    market_basket = l[0][real_order_mask]\n",
    "    market_basket = np.array([k for k,g in itertools.groupby(market_basket)]) # collapse adjacent identic elements\n",
    "    if market_basket.shape[0] == 1:\n",
    "        continue\n",
    "        \n",
    "    if (1387 in market_basket) and (87 in market_basket):\n",
    "        d.append(market_basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_mco = np.zeros((29000,29000))\n",
    "for v in d:\n",
    "    sc_mco = add_vect_to_mco(sc_mco, v)\n",
    "print(sc_mco[2,9])\n",
    "print(sc_mco[9,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mco[1387].argsort()[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mco2 = np.load('mco.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mco2[1387].argsort()[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mco2[1387,43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13029197080291971"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mco[1387].max() / sum(mco[1387])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14385.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
