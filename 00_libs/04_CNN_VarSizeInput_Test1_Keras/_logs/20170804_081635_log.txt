[FCNLIB][2017-08-04 08:16:35] Library [FCNLIB] initialized on machine [HPC]
[FCNLIB][2017-08-04 08:16:36] Training/testing a total of 6 models

[FCNLIB][2017-08-04 08:16:36] Preparing FCN (1/6): 16x2->32x2->128(1)x1->GMP->512->512 using model blocks definition 
[FCNLIB][2017-08-04 08:16:37] Short description:
Input (None, None, 1)
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:128 kernel:(1, 1) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
GlobalMaxPooling2D
Dense   [unit:256 activ:elu init:he_normal]
Dense   [unit:256 activ:elu init:he_normal]
Readout [unit:10 activ:softmax init:he_normal]

[FCNLIB][2017-08-04 08:16:37] Keras Neural Network Layout
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, None, None, 1)     0         
_________________________________________________________________
CBLOCK1_CONV16_0 (Conv2D)    (None, None, None, 16)    160       
_________________________________________________________________
batch_normalization_6 (Batch (None, None, None, 16)    64        
_________________________________________________________________
activation_6 (Activation)    (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK1_CONV16_1 (Conv2D)    (None, None, None, 16)    2320      
_________________________________________________________________
batch_normalization_7 (Batch (None, None, None, 16)    64        
_________________________________________________________________
activation_7 (Activation)    (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK2_CONV32_0 (Conv2D)    (None, None, None, 32)    4640      
_________________________________________________________________
batch_normalization_8 (Batch (None, None, None, 32)    128       
_________________________________________________________________
activation_8 (Activation)    (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK2_CONV32_1 (Conv2D)    (None, None, None, 32)    9248      
_________________________________________________________________
batch_normalization_9 (Batch (None, None, None, 32)    128       
_________________________________________________________________
activation_9 (Activation)    (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK3_CONV128_0 (Conv2D)   (None, None, None, 128)   4224      
_________________________________________________________________
batch_normalization_10 (Batc (None, None, None, 128)   512       
_________________________________________________________________
activation_10 (Activation)   (None, None, None, 128)   0         
_________________________________________________________________
global_max_pooling2d_2 (Glob (None, 128)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 256)               33024     
_________________________________________________________________
dense_5 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_6 (Dense)              (None, 10)                2570      
=================================================================
Total params: 122,874.0
Trainable params: 122,426.0
Non-trainable params: 448.0
_________________________________________________________________

[FCNLIB][2017-08-04 08:16:37] Training network for 10 epochs...
[FCNLIB][2017-08-04 08:20:11] Test score:0.055
[FCNLIB][2017-08-04 08:20:11] Test accuracy:0.983
[FCNLIB][2017-08-04 08:20:11] Label/Prediction: 7/2 Correct: False Imagesize: (1, 127, 82, 1)
[FCNLIB][2017-08-04 08:20:11]   Prediction: [ 0.00  0.00  0.81  0.01  0.00  0.00  0.00  0.17  0.00  0.00]
[FCNLIB][2017-08-04 08:20:11]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:11] Saving figure [_output\20170804_082011_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_7_2.png]
[FCNLIB][2017-08-04 08:20:12] Label/Prediction: 3/5 Correct: False Imagesize: (1, 110, 106, 1)
[FCNLIB][2017-08-04 08:20:12]   Prediction: [ 0.00  0.00  0.00  0.41  0.00  0.59  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:12]   y_test:     [ 0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:12] Saving figure [_output\20170804_082012_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_3_5.png]
[FCNLIB][2017-08-04 08:20:13] Label/Prediction: 1/3 Correct: False Imagesize: (1, 126, 84, 1)
[FCNLIB][2017-08-04 08:20:13]   Prediction: [ 0.24  0.27  0.03  0.44  0.00  0.01  0.00  0.00  0.02  0.00]
[FCNLIB][2017-08-04 08:20:13]   y_test:     [ 0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:13] Saving figure [_output\20170804_082013_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_1_3.png]
[FCNLIB][2017-08-04 08:20:14] Label/Prediction: 9/4 Correct: False Imagesize: (1, 100, 113, 1)
[FCNLIB][2017-08-04 08:20:14]   Prediction: [ 0.00  0.00  0.00  0.00  0.96  0.00  0.00  0.00  0.00  0.03]
[FCNLIB][2017-08-04 08:20:14]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:20:14] Saving figure [_output\20170804_082014_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:20:17] Label/Prediction: 9/4 Correct: False Imagesize: (1, 102, 125, 1)
[FCNLIB][2017-08-04 08:20:17]   Prediction: [ 0.00  0.00  0.01  0.00  0.56  0.00  0.00  0.00  0.00  0.43]
[FCNLIB][2017-08-04 08:20:17]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:20:17] Saving figure [_output\20170804_082017_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:20:18] Label/Prediction: 6/0 Correct: False Imagesize: (1, 92, 79, 1)
[FCNLIB][2017-08-04 08:20:18]   Prediction: [ 0.52  0.00  0.00  0.00  0.00  0.32  0.15  0.00  0.01  0.00]
[FCNLIB][2017-08-04 08:20:18]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:18] Saving figure [_output\20170804_082018_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_6_0.png]
[FCNLIB][2017-08-04 08:20:20] Label/Prediction: 2/3 Correct: False Imagesize: (1, 89, 106, 1)
[FCNLIB][2017-08-04 08:20:20]   Prediction: [ 0.00  0.00  0.43  0.57  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:20]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:20] Saving figure [_output\20170804_082020_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_2_3.png]
[FCNLIB][2017-08-04 08:20:20] Label/Prediction: 2/3 Correct: False Imagesize: (1, 92, 85, 1)
[FCNLIB][2017-08-04 08:20:20]   Prediction: [ 0.00  0.00  0.24  0.75  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:20]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:20] Saving figure [_output\20170804_082020_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_2_3.png]
[FCNLIB][2017-08-04 08:20:20] Aborting image saving. File already exists.
[FCNLIB][2017-08-04 08:20:21] Label/Prediction: 5/9 Correct: False Imagesize: (1, 123, 89, 1)
[FCNLIB][2017-08-04 08:20:21]   Prediction: [ 0.00  0.00  0.00  0.00  0.00  0.37  0.00  0.00  0.00  0.63]
[FCNLIB][2017-08-04 08:20:21]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:21] Saving figure [_output\20170804_082021_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_5_9.png]
[FCNLIB][2017-08-04 08:20:22] Label/Prediction: 9/2 Correct: False Imagesize: (1, 127, 121, 1)
[FCNLIB][2017-08-04 08:20:22]   Prediction: [ 0.00  0.00  0.91  0.00  0.00  0.00  0.00  0.00  0.00  0.09]
[FCNLIB][2017-08-04 08:20:22]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:20:22] Saving figure [_output\20170804_082022_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_9_2.png]
[FCNLIB][2017-08-04 08:20:26] Label/Prediction: 6/0 Correct: False Imagesize: (1, 92, 124, 1)
[FCNLIB][2017-08-04 08:20:26]   Prediction: [ 0.61  0.00  0.00  0.00  0.00  0.00  0.37  0.00  0.00  0.01]
[FCNLIB][2017-08-04 08:20:26]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:20:26] Saving figure [_output\20170804_082026_16x2-_32x2-_128(1)x1-_GMP-_512-_512_WRONG_LABEL_6_0.png]
[FCNLIB][2017-08-04 08:20:27] Variable size accuracy: 0.978 (test 0.983)for 16x2->32x2->128(1)x1->GMP->512->512

[FCNLIB][2017-08-04 08:20:27] Preparing FCN (2/6): 16x2->32x2->128(3)x1->GMP->512->512 using model blocks definition 
[FCNLIB][2017-08-04 08:20:28] Short description:
Input (None, None, 1)
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:128 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
GlobalMaxPooling2D
Dense   [unit:256 activ:elu init:he_normal]
Dense   [unit:256 activ:elu init:he_normal]
Readout [unit:10 activ:softmax init:he_normal]

[FCNLIB][2017-08-04 08:20:28] Keras Neural Network Layout
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, None, None, 1)     0         
_________________________________________________________________
CBLOCK1_CONV16_0 (Conv2D)    (None, None, None, 16)    160       
_________________________________________________________________
batch_normalization_11 (Batc (None, None, None, 16)    64        
_________________________________________________________________
activation_11 (Activation)   (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK1_CONV16_1 (Conv2D)    (None, None, None, 16)    2320      
_________________________________________________________________
batch_normalization_12 (Batc (None, None, None, 16)    64        
_________________________________________________________________
activation_12 (Activation)   (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK2_CONV32_0 (Conv2D)    (None, None, None, 32)    4640      
_________________________________________________________________
batch_normalization_13 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_13 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK2_CONV32_1 (Conv2D)    (None, None, None, 32)    9248      
_________________________________________________________________
batch_normalization_14 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_14 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK3_CONV128_0 (Conv2D)   (None, None, None, 128)   36992     
_________________________________________________________________
batch_normalization_15 (Batc (None, None, None, 128)   512       
_________________________________________________________________
activation_15 (Activation)   (None, None, None, 128)   0         
_________________________________________________________________
global_max_pooling2d_3 (Glob (None, 128)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 256)               33024     
_________________________________________________________________
dense_8 (Dense)              (None, 256)               65792     
_________________________________________________________________
dense_9 (Dense)              (None, 10)                2570      
=================================================================
Total params: 155,642.0
Trainable params: 155,194.0
Non-trainable params: 448.0
_________________________________________________________________

[FCNLIB][2017-08-04 08:20:29] Training network for 10 epochs...
[FCNLIB][2017-08-04 08:22:31] Test score:0.058
[FCNLIB][2017-08-04 08:22:31] Test accuracy:0.983
[FCNLIB][2017-08-04 08:22:33] Label/Prediction: 3/5 Correct: False Imagesize: (1, 110, 106, 1)
[FCNLIB][2017-08-04 08:22:33]   Prediction: [ 0.00  0.00  0.00  0.02  0.00  0.98  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:33]   y_test:     [ 0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:33] Saving figure [_output\20170804_082233_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_3_5.png]
[FCNLIB][2017-08-04 08:22:33] Label/Prediction: 8/5 Correct: False Imagesize: (1, 86, 92, 1)
[FCNLIB][2017-08-04 08:22:33]   Prediction: [ 0.00  0.00  0.00  0.00  0.00  0.54  0.04  0.00  0.41  0.00]
[FCNLIB][2017-08-04 08:22:33]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00]
[FCNLIB][2017-08-04 08:22:33] Saving figure [_output\20170804_082233_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_8_5.png]
[FCNLIB][2017-08-04 08:22:33] Label/Prediction: 2/5 Correct: False Imagesize: (1, 122, 111, 1)
[FCNLIB][2017-08-04 08:22:33]   Prediction: [ 0.00  0.00  0.02  0.02  0.00  0.97  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:33]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:33] Saving figure [_output\20170804_082233_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_2_5.png]
[FCNLIB][2017-08-04 08:22:33] Label/Prediction: 9/5 Correct: False Imagesize: (1, 103, 99, 1)
[FCNLIB][2017-08-04 08:22:33]   Prediction: [ 0.01  0.00  0.00  0.00  0.00  0.71  0.00  0.00  0.02  0.26]
[FCNLIB][2017-08-04 08:22:33]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:22:33] Saving figure [_output\20170804_082233_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_9_5.png]
[FCNLIB][2017-08-04 08:22:34] Label/Prediction: 8/5 Correct: False Imagesize: (1, 119, 100, 1)
[FCNLIB][2017-08-04 08:22:34]   Prediction: [ 0.00  0.00  0.00  0.00  0.00  0.54  0.04  0.00  0.41  0.00]
[FCNLIB][2017-08-04 08:22:34]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00]
[FCNLIB][2017-08-04 08:22:34] Saving figure [_output\20170804_082234_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_8_5.png]
[FCNLIB][2017-08-04 08:22:34] Label/Prediction: 9/4 Correct: False Imagesize: (1, 100, 113, 1)
[FCNLIB][2017-08-04 08:22:34]   Prediction: [ 0.00  0.00  0.00  0.00  0.98  0.00  0.00  0.00  0.00  0.02]
[FCNLIB][2017-08-04 08:22:34]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:22:34] Saving figure [_output\20170804_082234_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:22:36] Label/Prediction: 0/5 Correct: False Imagesize: (1, 101, 93, 1)
[FCNLIB][2017-08-04 08:22:36]   Prediction: [ 0.12  0.00  0.00  0.03  0.00  0.82  0.00  0.00  0.01  0.00]
[FCNLIB][2017-08-04 08:22:36]   y_test:     [ 1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:36] Saving figure [_output\20170804_082236_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_0_5.png]
[FCNLIB][2017-08-04 08:22:39] Label/Prediction: 2/3 Correct: False Imagesize: (1, 108, 113, 1)
[FCNLIB][2017-08-04 08:22:39]   Prediction: [ 0.00  0.00  0.32  0.52  0.00  0.00  0.00  0.16  0.00  0.00]
[FCNLIB][2017-08-04 08:22:39]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:39] Saving figure [_output\20170804_082239_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_2_3.png]
[FCNLIB][2017-08-04 08:22:40] Label/Prediction: 8/5 Correct: False Imagesize: (1, 127, 106, 1)
[FCNLIB][2017-08-04 08:22:40]   Prediction: [ 0.00  0.00  0.00  0.00  0.00  0.54  0.04  0.00  0.41  0.00]
[FCNLIB][2017-08-04 08:22:40]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00]
[FCNLIB][2017-08-04 08:22:40] Saving figure [_output\20170804_082240_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_8_5.png]
[FCNLIB][2017-08-04 08:22:41] Label/Prediction: 2/5 Correct: False Imagesize: (1, 110, 118, 1)
[FCNLIB][2017-08-04 08:22:41]   Prediction: [ 0.00  0.00  0.39  0.00  0.00  0.50  0.00  0.00  0.09  0.01]
[FCNLIB][2017-08-04 08:22:41]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:41] Saving figure [_output\20170804_082241_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_2_5.png]
[FCNLIB][2017-08-04 08:22:46] Label/Prediction: 2/8 Correct: False Imagesize: (1, 105, 115, 1)
[FCNLIB][2017-08-04 08:22:46]   Prediction: [ 0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.89  0.00]
[FCNLIB][2017-08-04 08:22:46]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:22:46] Saving figure [_output\20170804_082246_16x2-_32x2-_128(3)x1-_GMP-_512-_512_WRONG_LABEL_2_8.png]
[FCNLIB][2017-08-04 08:22:46] Variable size accuracy: 0.978 (test 0.983)for 16x2->32x2->128(3)x1->GMP->512->512

[FCNLIB][2017-08-04 08:22:46] Preparing FCN (3/6): 32x2->64x2->512(1)x2->GMP->512d->512d using model blocks definition 
[FCNLIB][2017-08-04 08:22:47] Short description:
Input (None, None, 1)
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:512 kernel:(1, 1) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:512 kernel:(1, 1) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
GlobalMaxPooling2D
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Readout [unit:10 activ:softmax init:he_normal]

[FCNLIB][2017-08-04 08:22:47] Keras Neural Network Layout
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_4 (InputLayer)         (None, None, None, 1)     0         
_________________________________________________________________
CBLOCK1_CONV32_0 (Conv2D)    (None, None, None, 32)    320       
_________________________________________________________________
batch_normalization_16 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_16 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK1_CONV32_1 (Conv2D)    (None, None, None, 32)    9248      
_________________________________________________________________
batch_normalization_17 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_17 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK2_CONV64_0 (Conv2D)    (None, None, None, 64)    18496     
_________________________________________________________________
batch_normalization_18 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_18 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK2_CONV64_1 (Conv2D)    (None, None, None, 64)    36928     
_________________________________________________________________
batch_normalization_19 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_19 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK3_CONV512_0 (Conv2D)   (None, None, None, 512)   33280     
_________________________________________________________________
batch_normalization_20 (Batc (None, None, None, 512)   2048      
_________________________________________________________________
activation_20 (Activation)   (None, None, None, 512)   0         
_________________________________________________________________
CBLOCK3_CONV512_1 (Conv2D)   (None, None, None, 512)   262656    
_________________________________________________________________
batch_normalization_21 (Batc (None, None, None, 512)   2048      
_________________________________________________________________
activation_21 (Activation)   (None, None, None, 512)   0         
_________________________________________________________________
global_max_pooling2d_4 (Glob (None, 512)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 512)               262656    
_________________________________________________________________
dropout_1 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 512)               262656    
_________________________________________________________________
dropout_2 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_12 (Dense)             (None, 10)                5130      
=================================================================
Total params: 896,234.0
Trainable params: 893,802.0
Non-trainable params: 2,432.0
_________________________________________________________________

[FCNLIB][2017-08-04 08:22:47] Training network for 10 epochs...
[FCNLIB][2017-08-04 08:29:38] Test score:0.058
[FCNLIB][2017-08-04 08:29:38] Test accuracy:0.982
[FCNLIB][2017-08-04 08:29:39] Label/Prediction: 7/2 Correct: False Imagesize: (1, 127, 82, 1)
[FCNLIB][2017-08-04 08:29:39]   Prediction: [ 0.00  0.01  0.51  0.00  0.01  0.00  0.00  0.47  0.00  0.00]
[FCNLIB][2017-08-04 08:29:39]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00]
[FCNLIB][2017-08-04 08:29:39] Saving figure [_output\20170804_082939_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_7_2.png]
[FCNLIB][2017-08-04 08:29:40] Label/Prediction: 3/5 Correct: False Imagesize: (1, 110, 106, 1)
[FCNLIB][2017-08-04 08:29:40]   Prediction: [ 0.00  0.00  0.00  0.09  0.00  0.86  0.00  0.02  0.02  0.00]
[FCNLIB][2017-08-04 08:29:40]   y_test:     [ 0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:29:40] Saving figure [_output\20170804_082940_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_3_5.png]
[FCNLIB][2017-08-04 08:29:41] Label/Prediction: 1/8 Correct: False Imagesize: (1, 126, 84, 1)
[FCNLIB][2017-08-04 08:29:41]   Prediction: [ 0.03  0.03  0.13  0.07  0.03  0.08  0.00  0.05  0.55  0.03]
[FCNLIB][2017-08-04 08:29:41]   y_test:     [ 0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:29:41] Saving figure [_output\20170804_082941_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_1_8.png]
[FCNLIB][2017-08-04 08:29:43] Label/Prediction: 9/4 Correct: False Imagesize: (1, 100, 113, 1)
[FCNLIB][2017-08-04 08:29:43]   Prediction: [ 0.00  0.00  0.00  0.00  0.88  0.00  0.00  0.00  0.04  0.08]
[FCNLIB][2017-08-04 08:29:43]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:29:43] Saving figure [_output\20170804_082943_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:29:44] Label/Prediction: 7/2 Correct: False Imagesize: (1, 127, 90, 1)
[FCNLIB][2017-08-04 08:29:44]   Prediction: [ 0.00  0.00  0.75  0.00  0.00  0.00  0.00  0.25  0.00  0.00]
[FCNLIB][2017-08-04 08:29:44]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00]
[FCNLIB][2017-08-04 08:29:44] Saving figure [_output\20170804_082944_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_7_2.png]
[FCNLIB][2017-08-04 08:29:48] Label/Prediction: 9/4 Correct: False Imagesize: (1, 125, 112, 1)
[FCNLIB][2017-08-04 08:29:48]   Prediction: [ 0.04  0.00  0.16  0.00  0.44  0.00  0.00  0.01  0.05  0.31]
[FCNLIB][2017-08-04 08:29:48]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:29:48] Saving figure [_output\20170804_082948_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:29:49] Label/Prediction: 6/4 Correct: False Imagesize: (1, 80, 121, 1)
[FCNLIB][2017-08-04 08:29:49]   Prediction: [ 0.02  0.00  0.00  0.00  0.83  0.00  0.08  0.00  0.07  0.00]
[FCNLIB][2017-08-04 08:29:49]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:29:49] Saving figure [_output\20170804_082949_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_6_4.png]
[FCNLIB][2017-08-04 08:29:49] Label/Prediction: 9/4 Correct: False Imagesize: (1, 83, 98, 1)
[FCNLIB][2017-08-04 08:29:49]   Prediction: [ 0.04  0.00  0.16  0.00  0.44  0.00  0.00  0.01  0.05  0.31]
[FCNLIB][2017-08-04 08:29:49]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:29:49] Saving figure [_output\20170804_082949_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:29:50] Label/Prediction: 1/4 Correct: False Imagesize: (1, 91, 82, 1)
[FCNLIB][2017-08-04 08:29:50]   Prediction: [ 0.03  0.10  0.01  0.00  0.55  0.00  0.17  0.00  0.15  0.00]
[FCNLIB][2017-08-04 08:29:50]   y_test:     [ 0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:29:50] Saving figure [_output\20170804_082950_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_1_4.png]
[FCNLIB][2017-08-04 08:29:53] Label/Prediction: 9/4 Correct: False Imagesize: (1, 106, 121, 1)
[FCNLIB][2017-08-04 08:29:53]   Prediction: [ 0.00  0.00  0.00  0.00  0.82  0.00  0.00  0.00  0.02  0.16]
[FCNLIB][2017-08-04 08:29:53]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:29:53] Saving figure [_output\20170804_082953_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:29:55] Label/Prediction: 9/8 Correct: False Imagesize: (1, 103, 118, 1)
[FCNLIB][2017-08-04 08:29:55]   Prediction: [ 0.00  0.00  0.05  0.00  0.05  0.01  0.00  0.00  0.81  0.07]
[FCNLIB][2017-08-04 08:29:55]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:29:55] Saving figure [_output\20170804_082955_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_9_8.png]
[FCNLIB][2017-08-04 08:30:03] Label/Prediction: 6/2 Correct: False Imagesize: (1, 83, 105, 1)
[FCNLIB][2017-08-04 08:30:03]   Prediction: [ 0.21  0.01  0.40  0.00  0.09  0.06  0.20  0.00  0.02  0.00]
[FCNLIB][2017-08-04 08:30:03]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:30:03] Saving figure [_output\20170804_083003_32x2-_64x2-_512(1)x2-_GMP-_512d-_512d_WRONG_LABEL_6_2.png]
[FCNLIB][2017-08-04 08:30:03] Variable size accuracy: 0.976 (test 0.982)for 32x2->64x2->512(1)x2->GMP->512d->512d

[FCNLIB][2017-08-04 08:30:03] Preparing FCN (4/6): 32x2->64x2->512(3)x2->GMP->512d->512d using model blocks definition 
[FCNLIB][2017-08-04 08:30:04] Short description:
Input (None, None, 1)
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:512 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:512 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
GlobalMaxPooling2D
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Readout [unit:10 activ:softmax init:he_normal]

[FCNLIB][2017-08-04 08:30:04] Keras Neural Network Layout
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         (None, None, None, 1)     0         
_________________________________________________________________
CBLOCK1_CONV32_0 (Conv2D)    (None, None, None, 32)    320       
_________________________________________________________________
batch_normalization_22 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_22 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK1_CONV32_1 (Conv2D)    (None, None, None, 32)    9248      
_________________________________________________________________
batch_normalization_23 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_23 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK2_CONV64_0 (Conv2D)    (None, None, None, 64)    18496     
_________________________________________________________________
batch_normalization_24 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_24 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK2_CONV64_1 (Conv2D)    (None, None, None, 64)    36928     
_________________________________________________________________
batch_normalization_25 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_25 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK3_CONV512_0 (Conv2D)   (None, None, None, 512)   295424    
_________________________________________________________________
batch_normalization_26 (Batc (None, None, None, 512)   2048      
_________________________________________________________________
activation_26 (Activation)   (None, None, None, 512)   0         
_________________________________________________________________
CBLOCK3_CONV512_1 (Conv2D)   (None, None, None, 512)   2359808   
_________________________________________________________________
batch_normalization_27 (Batc (None, None, None, 512)   2048      
_________________________________________________________________
activation_27 (Activation)   (None, None, None, 512)   0         
_________________________________________________________________
global_max_pooling2d_5 (Glob (None, 512)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 512)               262656    
_________________________________________________________________
dropout_3 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 512)               262656    
_________________________________________________________________
dropout_4 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_15 (Dense)             (None, 10)                5130      
=================================================================
Total params: 3,255,530.0
Trainable params: 3,253,098.0
Non-trainable params: 2,432.0
_________________________________________________________________

[FCNLIB][2017-08-04 08:30:04] Training network for 10 epochs...
[FCNLIB][2017-08-04 08:43:37] Test score:0.056
[FCNLIB][2017-08-04 08:43:37] Test accuracy:0.985
[FCNLIB][2017-08-04 08:43:46] Label/Prediction: 1/8 Correct: False Imagesize: (1, 126, 84, 1)
[FCNLIB][2017-08-04 08:43:46]   Prediction: [ 0.02  0.03  0.21  0.04  0.05  0.01  0.02  0.02  0.61  0.00]
[FCNLIB][2017-08-04 08:43:46]   y_test:     [ 0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:43:46] Saving figure [_output\20170804_084346_32x2-_64x2-_512(3)x2-_GMP-_512d-_512d_WRONG_LABEL_1_8.png]
[FCNLIB][2017-08-04 08:43:56] Label/Prediction: 9/4 Correct: False Imagesize: (1, 100, 113, 1)
[FCNLIB][2017-08-04 08:43:56]   Prediction: [ 0.00  0.00  0.00  0.00  0.93  0.00  0.00  0.00  0.01  0.06]
[FCNLIB][2017-08-04 08:43:56]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:43:56] Saving figure [_output\20170804_084356_32x2-_64x2-_512(3)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:44:39] Label/Prediction: 9/4 Correct: False Imagesize: (1, 106, 121, 1)
[FCNLIB][2017-08-04 08:44:39]   Prediction: [ 0.00  0.00  0.00  0.00  0.51  0.00  0.00  0.00  0.01  0.47]
[FCNLIB][2017-08-04 08:44:39]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:44:39] Saving figure [_output\20170804_084439_32x2-_64x2-_512(3)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:44:50] Label/Prediction: 5/2 Correct: False Imagesize: (1, 123, 113, 1)
[FCNLIB][2017-08-04 08:44:50]   Prediction: [ 0.00  0.10  0.60  0.02  0.00  0.27  0.00  0.01  0.00  0.00]
[FCNLIB][2017-08-04 08:44:50]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:44:50] Saving figure [_output\20170804_084450_32x2-_64x2-_512(3)x2-_GMP-_512d-_512d_WRONG_LABEL_5_2.png]
[FCNLIB][2017-08-04 08:45:25] Variable size accuracy: 0.992 (test 0.985)for 32x2->64x2->512(3)x2->GMP->512d->512d

[FCNLIB][2017-08-04 08:45:25] Preparing FCN (5/6): 16x2->32x2->64x2->128x2->256(3)x2->GMP->512d->512d using model blocks definition 
[FCNLIB][2017-08-04 08:45:26] Short description:
Input (None, None, 1)
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:128 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:128 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:256 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:256 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
GlobalMaxPooling2D
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Readout [unit:10 activ:softmax init:he_normal]

[FCNLIB][2017-08-04 08:45:26] Keras Neural Network Layout
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, None, None, 1)     0         
_________________________________________________________________
CBLOCK1_CONV16_0 (Conv2D)    (None, None, None, 16)    160       
_________________________________________________________________
batch_normalization_28 (Batc (None, None, None, 16)    64        
_________________________________________________________________
activation_28 (Activation)   (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK1_CONV16_1 (Conv2D)    (None, None, None, 16)    2320      
_________________________________________________________________
batch_normalization_29 (Batc (None, None, None, 16)    64        
_________________________________________________________________
activation_29 (Activation)   (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK2_CONV32_0 (Conv2D)    (None, None, None, 32)    4640      
_________________________________________________________________
batch_normalization_30 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_30 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK2_CONV32_1 (Conv2D)    (None, None, None, 32)    9248      
_________________________________________________________________
batch_normalization_31 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_31 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK3_CONV64_0 (Conv2D)    (None, None, None, 64)    18496     
_________________________________________________________________
batch_normalization_32 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_32 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK3_CONV64_1 (Conv2D)    (None, None, None, 64)    36928     
_________________________________________________________________
batch_normalization_33 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_33 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK4_CONV128_0 (Conv2D)   (None, None, None, 128)   73856     
_________________________________________________________________
batch_normalization_34 (Batc (None, None, None, 128)   512       
_________________________________________________________________
activation_34 (Activation)   (None, None, None, 128)   0         
_________________________________________________________________
CBLOCK4_CONV128_1 (Conv2D)   (None, None, None, 128)   147584    
_________________________________________________________________
batch_normalization_35 (Batc (None, None, None, 128)   512       
_________________________________________________________________
activation_35 (Activation)   (None, None, None, 128)   0         
_________________________________________________________________
CBLOCK5_CONV256_0 (Conv2D)   (None, None, None, 256)   295168    
_________________________________________________________________
batch_normalization_36 (Batc (None, None, None, 256)   1024      
_________________________________________________________________
activation_36 (Activation)   (None, None, None, 256)   0         
_________________________________________________________________
CBLOCK5_CONV256_1 (Conv2D)   (None, None, None, 256)   590080    
_________________________________________________________________
batch_normalization_37 (Batc (None, None, None, 256)   1024      
_________________________________________________________________
activation_37 (Activation)   (None, None, None, 256)   0         
_________________________________________________________________
global_max_pooling2d_6 (Glob (None, 256)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 512)               131584    
_________________________________________________________________
dropout_5 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 512)               262656    
_________________________________________________________________
dropout_6 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 10)                5130      
=================================================================
Total params: 1,581,818.0
Trainable params: 1,579,834.0
Non-trainable params: 1,984.0
_________________________________________________________________

[FCNLIB][2017-08-04 08:45:26] Training network for 10 epochs...
[FCNLIB][2017-08-04 08:57:06] Test score:0.137
[FCNLIB][2017-08-04 08:57:06] Test accuracy:0.963
[FCNLIB][2017-08-04 08:57:13] Label/Prediction: 2/1 Correct: False Imagesize: (1, 91, 110, 1)
[FCNLIB][2017-08-04 08:57:13]   Prediction: [ 0.00  0.83  0.13  0.00  0.02  0.00  0.00  0.02  0.00  0.00]
[FCNLIB][2017-08-04 08:57:13]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:13] Saving figure [_output\20170804_085713_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_1.png]
[FCNLIB][2017-08-04 08:57:13] Label/Prediction: 3/7 Correct: False Imagesize: (1, 110, 106, 1)
[FCNLIB][2017-08-04 08:57:13]   Prediction: [ 0.00  0.00  0.00  0.05  0.00  0.07  0.00  0.87  0.00  0.01]
[FCNLIB][2017-08-04 08:57:13]   y_test:     [ 0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:13] Saving figure [_output\20170804_085713_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_3_7.png]
[FCNLIB][2017-08-04 08:57:14] Label/Prediction: 2/7 Correct: False Imagesize: (1, 93, 101, 1)
[FCNLIB][2017-08-04 08:57:14]   Prediction: [ 0.00  0.00  0.05  0.00  0.00  0.00  0.00  0.95  0.00  0.00]
[FCNLIB][2017-08-04 08:57:14]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:14] Saving figure [_output\20170804_085714_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_7.png]
[FCNLIB][2017-08-04 08:57:18] Label/Prediction: 2/7 Correct: False Imagesize: (1, 80, 82, 1)
[FCNLIB][2017-08-04 08:57:18]   Prediction: [ 0.00  0.00  0.36  0.00  0.00  0.00  0.00  0.64  0.00  0.00]
[FCNLIB][2017-08-04 08:57:18]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:18] Saving figure [_output\20170804_085718_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_7.png]
[FCNLIB][2017-08-04 08:57:19] Label/Prediction: 3/7 Correct: False Imagesize: (1, 115, 89, 1)
[FCNLIB][2017-08-04 08:57:19]   Prediction: [ 0.00  0.02  0.00  0.29  0.04  0.07  0.00  0.30  0.00  0.27]
[FCNLIB][2017-08-04 08:57:19]   y_test:     [ 0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:19] Saving figure [_output\20170804_085719_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_3_7.png]
[FCNLIB][2017-08-04 08:57:25] Label/Prediction: 9/4 Correct: False Imagesize: (1, 100, 113, 1)
[FCNLIB][2017-08-04 08:57:25]   Prediction: [ 0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:25]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:57:25] Saving figure [_output\20170804_085725_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:57:32] Label/Prediction: 2/7 Correct: False Imagesize: (1, 119, 85, 1)
[FCNLIB][2017-08-04 08:57:32]   Prediction: [ 0.00  0.21  0.22  0.00  0.09  0.00  0.00  0.49  0.00  0.00]
[FCNLIB][2017-08-04 08:57:32]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:32] Saving figure [_output\20170804_085732_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_7.png]
[FCNLIB][2017-08-04 08:57:35] Label/Prediction: 2/4 Correct: False Imagesize: (1, 95, 110, 1)
[FCNLIB][2017-08-04 08:57:35]   Prediction: [ 0.00  0.07  0.02  0.00  0.90  0.00  0.00  0.01  0.00  0.00]
[FCNLIB][2017-08-04 08:57:35]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:35] Saving figure [_output\20170804_085735_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_4.png]
[FCNLIB][2017-08-04 08:57:40] Label/Prediction: 9/4 Correct: False Imagesize: (1, 102, 125, 1)
[FCNLIB][2017-08-04 08:57:40]   Prediction: [ 0.00  0.00  0.00  0.00  0.71  0.00  0.00  0.00  0.00  0.29]
[FCNLIB][2017-08-04 08:57:40]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:57:40] Saving figure [_output\20170804_085740_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:57:43] Label/Prediction: 2/4 Correct: False Imagesize: (1, 102, 124, 1)
[FCNLIB][2017-08-04 08:57:43]   Prediction: [ 0.00  0.03  0.01  0.00  0.68  0.00  0.00  0.29  0.00  0.00]
[FCNLIB][2017-08-04 08:57:43]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:43] Saving figure [_output\20170804_085743_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_4.png]
[FCNLIB][2017-08-04 08:57:46] Label/Prediction: 6/4 Correct: False Imagesize: (1, 80, 121, 1)
[FCNLIB][2017-08-04 08:57:46]   Prediction: [ 0.00  0.00  0.00  0.00  0.99  0.00  0.01  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:46]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:46] Saving figure [_output\20170804_085746_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_6_4.png]
[FCNLIB][2017-08-04 08:57:51] Label/Prediction: 2/7 Correct: False Imagesize: (1, 78, 101, 1)
[FCNLIB][2017-08-04 08:57:51]   Prediction: [ 0.00  0.05  0.18  0.00  0.14  0.00  0.00  0.63  0.00  0.00]
[FCNLIB][2017-08-04 08:57:51]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:57:51] Saving figure [_output\20170804_085751_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_7.png]
[FCNLIB][2017-08-04 08:57:52] Label/Prediction: 8/5 Correct: False Imagesize: (1, 127, 92, 1)
[FCNLIB][2017-08-04 08:57:52]   Prediction: [ 0.00  0.00  0.00  0.00  0.00  0.95  0.00  0.00  0.05  0.00]
[FCNLIB][2017-08-04 08:57:52]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00]
[FCNLIB][2017-08-04 08:57:52] Saving figure [_output\20170804_085752_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_8_5.png]
[FCNLIB][2017-08-04 08:58:00] Label/Prediction: 2/7 Correct: False Imagesize: (1, 92, 85, 1)
[FCNLIB][2017-08-04 08:58:00]   Prediction: [ 0.00  0.00  0.17  0.00  0.00  0.00  0.00  0.82  0.00  0.00]
[FCNLIB][2017-08-04 08:58:00]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:58:00] Saving figure [_output\20170804_085800_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_7.png]
[FCNLIB][2017-08-04 08:58:24] Label/Prediction: 9/4 Correct: False Imagesize: (1, 126, 111, 1)
[FCNLIB][2017-08-04 08:58:24]   Prediction: [ 0.00  0.00  0.00  0.00  0.94  0.00  0.00  0.00  0.00  0.06]
[FCNLIB][2017-08-04 08:58:24]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:58:24] Saving figure [_output\20170804_085824_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:58:26] Label/Prediction: 9/4 Correct: False Imagesize: (1, 116, 90, 1)
[FCNLIB][2017-08-04 08:58:26]   Prediction: [ 0.00  0.00  0.00  0.00  0.97  0.00  0.00  0.00  0.00  0.03]
[FCNLIB][2017-08-04 08:58:26]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 08:58:26] Saving figure [_output\20170804_085826_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 08:58:31] Label/Prediction: 2/1 Correct: False Imagesize: (1, 107, 111, 1)
[FCNLIB][2017-08-04 08:58:31]   Prediction: [ 0.00  0.84  0.02  0.00  0.05  0.00  0.00  0.10  0.00  0.00]
[FCNLIB][2017-08-04 08:58:31]   y_test:     [ 0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:58:31] Saving figure [_output\20170804_085831_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_2_1.png]
[FCNLIB][2017-08-04 08:58:41] Label/Prediction: 6/4 Correct: False Imagesize: (1, 83, 105, 1)
[FCNLIB][2017-08-04 08:58:41]   Prediction: [ 0.00  0.00  0.00  0.00  0.72  0.00  0.28  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:58:41]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 08:58:41] Saving figure [_output\20170804_085841_16x2-_32x2-_64x2-_128x2-_256(3)x2-_GMP-_512d-_512d_WRONG_LABEL_6_4.png]
[FCNLIB][2017-08-04 08:58:41] Variable size accuracy: 0.964 (test 0.963)for 16x2->32x2->64x2->128x2->256(3)x2->GMP->512d->512d

[FCNLIB][2017-08-04 08:58:41] Preparing FCN (6/6): 16x2->32x2->64x2->128x2->256(1)x2->GMP->512d->512d using model blocks definition 
[FCNLIB][2017-08-04 08:58:43] Short description:
Input (None, None, 1)
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:16 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:32 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:64 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:128 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:128 kernel:(3, 3) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:256 kernel:(1, 1) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
Conv2D  [depth:256 kernel:(1, 1) stride:(1, 1) pad:same init:he_normal batchnorm:1 activ:elu]
GlobalMaxPooling2D
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Dense   [unit:512 activ:elu init:he_normal]
 Dropout [rate: 0.50]
Readout [unit:10 activ:softmax init:he_normal]

[FCNLIB][2017-08-04 08:58:43] Keras Neural Network Layout
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_7 (InputLayer)         (None, None, None, 1)     0         
_________________________________________________________________
CBLOCK1_CONV16_0 (Conv2D)    (None, None, None, 16)    160       
_________________________________________________________________
batch_normalization_38 (Batc (None, None, None, 16)    64        
_________________________________________________________________
activation_38 (Activation)   (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK1_CONV16_1 (Conv2D)    (None, None, None, 16)    2320      
_________________________________________________________________
batch_normalization_39 (Batc (None, None, None, 16)    64        
_________________________________________________________________
activation_39 (Activation)   (None, None, None, 16)    0         
_________________________________________________________________
CBLOCK2_CONV32_0 (Conv2D)    (None, None, None, 32)    4640      
_________________________________________________________________
batch_normalization_40 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_40 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK2_CONV32_1 (Conv2D)    (None, None, None, 32)    9248      
_________________________________________________________________
batch_normalization_41 (Batc (None, None, None, 32)    128       
_________________________________________________________________
activation_41 (Activation)   (None, None, None, 32)    0         
_________________________________________________________________
CBLOCK3_CONV64_0 (Conv2D)    (None, None, None, 64)    18496     
_________________________________________________________________
batch_normalization_42 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_42 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK3_CONV64_1 (Conv2D)    (None, None, None, 64)    36928     
_________________________________________________________________
batch_normalization_43 (Batc (None, None, None, 64)    256       
_________________________________________________________________
activation_43 (Activation)   (None, None, None, 64)    0         
_________________________________________________________________
CBLOCK4_CONV128_0 (Conv2D)   (None, None, None, 128)   73856     
_________________________________________________________________
batch_normalization_44 (Batc (None, None, None, 128)   512       
_________________________________________________________________
activation_44 (Activation)   (None, None, None, 128)   0         
_________________________________________________________________
CBLOCK4_CONV128_1 (Conv2D)   (None, None, None, 128)   147584    
_________________________________________________________________
batch_normalization_45 (Batc (None, None, None, 128)   512       
_________________________________________________________________
activation_45 (Activation)   (None, None, None, 128)   0         
_________________________________________________________________
CBLOCK5_CONV256_0 (Conv2D)   (None, None, None, 256)   33024     
_________________________________________________________________
batch_normalization_46 (Batc (None, None, None, 256)   1024      
_________________________________________________________________
activation_46 (Activation)   (None, None, None, 256)   0         
_________________________________________________________________
CBLOCK5_CONV256_1 (Conv2D)   (None, None, None, 256)   65792     
_________________________________________________________________
batch_normalization_47 (Batc (None, None, None, 256)   1024      
_________________________________________________________________
activation_47 (Activation)   (None, None, None, 256)   0         
_________________________________________________________________
global_max_pooling2d_7 (Glob (None, 256)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 512)               131584    
_________________________________________________________________
dropout_7 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 512)               262656    
_________________________________________________________________
dropout_8 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_21 (Dense)             (None, 10)                5130      
=================================================================
Total params: 795,386.0
Trainable params: 793,402.0
Non-trainable params: 1,984.0
_________________________________________________________________

[FCNLIB][2017-08-04 08:58:43] Training network for 10 epochs...
[FCNLIB][2017-08-04 09:06:26] Test score:0.032
[FCNLIB][2017-08-04 09:06:26] Test accuracy:0.991
[FCNLIB][2017-08-04 09:06:28] Label/Prediction: 3/5 Correct: False Imagesize: (1, 110, 106, 1)
[FCNLIB][2017-08-04 09:06:28]   Prediction: [ 0.00  0.00  0.00  0.12  0.00  0.88  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 09:06:28]   y_test:     [ 0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 09:06:28] Saving figure [_output\20170804_090628_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_3_5.png]
[FCNLIB][2017-08-04 09:06:28] Label/Prediction: 9/4 Correct: False Imagesize: (1, 100, 113, 1)
[FCNLIB][2017-08-04 09:06:28]   Prediction: [ 0.00  0.00  0.00  0.00  0.78  0.00  0.00  0.00  0.03  0.19]
[FCNLIB][2017-08-04 09:06:28]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00]
[FCNLIB][2017-08-04 09:06:28] Saving figure [_output\20170804_090628_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_9_4.png]
[FCNLIB][2017-08-04 09:06:28] Label/Prediction: 7/1 Correct: False Imagesize: (1, 116, 83, 1)
[FCNLIB][2017-08-04 09:06:28]   Prediction: [ 0.00  0.85  0.00  0.00  0.00  0.00  0.00  0.15  0.00  0.00]
[FCNLIB][2017-08-04 09:06:28]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00]
[FCNLIB][2017-08-04 09:06:28] Saving figure [_output\20170804_090628_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_7_1.png]
[FCNLIB][2017-08-04 09:06:30] Label/Prediction: 8/5 Correct: False Imagesize: (1, 127, 92, 1)
[FCNLIB][2017-08-04 09:06:30]   Prediction: [ 0.00  0.00  0.00  0.00  0.00  0.94  0.00  0.00  0.05  0.00]
[FCNLIB][2017-08-04 09:06:30]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00]
[FCNLIB][2017-08-04 09:06:30] Saving figure [_output\20170804_090630_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_8_5.png]
[FCNLIB][2017-08-04 09:06:31] Label/Prediction: 7/1 Correct: False Imagesize: (1, 95, 110, 1)
[FCNLIB][2017-08-04 09:06:31]   Prediction: [ 0.00  0.85  0.00  0.00  0.00  0.00  0.00  0.15  0.00  0.00]
[FCNLIB][2017-08-04 09:06:31]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00]
[FCNLIB][2017-08-04 09:06:31] Saving figure [_output\20170804_090631_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_7_1.png]
[FCNLIB][2017-08-04 09:06:31] Label/Prediction: 5/1 Correct: False Imagesize: (1, 123, 113, 1)
[FCNLIB][2017-08-04 09:06:31]   Prediction: [ 0.00  0.84  0.09  0.00  0.00  0.05  0.00  0.01  0.00  0.00]
[FCNLIB][2017-08-04 09:06:31]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 09:06:31] Saving figure [_output\20170804_090631_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_5_1.png]
[FCNLIB][2017-08-04 09:06:32] Label/Prediction: 6/4 Correct: False Imagesize: (1, 92, 96, 1)
[FCNLIB][2017-08-04 09:06:32]   Prediction: [ 0.00  0.00  0.00  0.00  0.89  0.00  0.07  0.00  0.03  0.00]
[FCNLIB][2017-08-04 09:06:32]   y_test:     [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  0.00]
[FCNLIB][2017-08-04 09:06:32] Saving figure [_output\20170804_090632_16x2-_32x2-_64x2-_128x2-_256(1)x2-_GMP-_512d-_512d_WRONG_LABEL_6_4.png]
[FCNLIB][2017-08-04 09:06:33] Variable size accuracy: 0.986 (test 0.991)for 16x2->32x2->64x2->128x2->256(1)x2->GMP->512d->512d

[FCNLIB][2017-08-04 09:06:33] Final results:
[FCNLIB][2017-08-04 08:20:27] Variable size accuracy: 0.978 (test 0.983)for 16x2->32x2->128(1)x1->GMP->512->512
[FCNLIB][2017-08-04 08:22:46] Variable size accuracy: 0.978 (test 0.983)for 16x2->32x2->128(3)x1->GMP->512->512
[FCNLIB][2017-08-04 08:30:03] Variable size accuracy: 0.976 (test 0.982)for 32x2->64x2->512(1)x2->GMP->512d->512d
[FCNLIB][2017-08-04 08:45:25] Variable size accuracy: 0.992 (test 0.985)for 32x2->64x2->512(3)x2->GMP->512d->512d
[FCNLIB][2017-08-04 08:58:41] Variable size accuracy: 0.964 (test 0.963)for 16x2->32x2->64x2->128x2->256(3)x2->GMP->512d->512d
[FCNLIB][2017-08-04 09:06:33] Variable size accuracy: 0.986 (test 0.991)for 16x2->32x2->64x2->128x2->256(1)x2->GMP->512d->512d
[FCNLIB][2017-08-04 09:06:33] Results table:
                                              Layout  Model  TestAcc  VarAcc
4  16x2->32x2->64x2->128x2->256(3)x2->GMP->512d->...      4    0.963   0.964
2              32x2->64x2->512(1)x2->GMP->512d->512d      2    0.982   0.976
0                16x2->32x2->128(1)x1->GMP->512->512      0    0.983   0.978
1                16x2->32x2->128(3)x1->GMP->512->512      1    0.983   0.978
5  16x2->32x2->64x2->128x2->256(1)x2->GMP->512d->...      5    0.991   0.986
3              32x2->64x2->512(3)x2->GMP->512d->512d      3    0.985   0.992

[FCNLIB][2017-08-04 09:06:33] Best accuracy 0.992 for model 32x2->64x2->512(3)x2->GMP->512d->512d with test acc: 0.985
